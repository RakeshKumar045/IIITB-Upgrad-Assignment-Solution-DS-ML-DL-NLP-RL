{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shasw\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "\n",
    "# for building DQN model\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  6.,  8.,  5.,  7.,  4.,  6.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[0][3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_state(state):\n",
    "    return ('-'.join(str(e) for e in state)).replace('nan','x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dict = collections.defaultdict(dict)\n",
    "States_track = collections.defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_tracking_states(): \n",
    "    samvalues = [((3,0,2),(3,1)),((1,6,3),(2,3)),((2,2,2),(3,2))] \n",
    "    #select any 4 Q-values \n",
    "    for q_value in samvalues: \n",
    "        state = Q_state(q_value[0]) \n",
    "        action = q_value[1] \n",
    "        states_track[state][action] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tracking_states():\n",
    "    for state in States_track.keys():\n",
    "        for action in States_track[state].keys():\n",
    "            if state in Q_dict and action in Q_dict[state]:\n",
    "                States_track[state][action].append(Q_dict[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN\n",
    "        self.discount_factor = 0.95\n",
    "        self.learning_rate = 0.01       \n",
    "        self.epsilon_max = 1\n",
    "        self.epsilon_decay =0.99 \n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        # Write your code here: Add layers to your neural nets       \n",
    "        \n",
    "        # hidden layers\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def get_action(self, state):\n",
    "    # Write your code here:        \n",
    "        poss_index, actions = env.requests(state)        \n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in Îµ after we generate each sample from the environment       \n",
    "        if np.random.rand() <= self.epsilon_max:\n",
    "            # explore: choose a random action from all possible actions            \n",
    "            action = random.choice(actions)\n",
    "            return action\n",
    "        else:\n",
    "            # choose the action with the highest q(s, a)\n",
    "            # the first index corresponds to the batch size, so\n",
    "            # reshape state to (1, state_size) so that the first index corresponds to the batch size\n",
    "            state_encode = env.state_encod_arch1(state)\n",
    "            state_batch = state_encode.reshape(1, self.state_size)\n",
    "            q_value = self.model.predict(state_batch)\n",
    "            qvalue = [q_value[0][index] for index in poss_index]\n",
    "            #print(\"poss_index\", poss_index, \" actions \", actions, \" state \",state)\n",
    "            if not poss_index:\n",
    "                return actions[0]\n",
    "            else:\n",
    "                index = np.argmax(qvalue)            \n",
    "                return actions[index]     \n",
    "     \n",
    "        \n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    \n",
    "    # pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \n",
    "        if len(self.memory) > self.batch_size:\n",
    "            # Sample batch from the memory\n",
    "            mini_batch = random.sample(self.memory, self.batch_size)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))# write here\n",
    "            update_input = np.zeros((self.batch_size, self.state_size)) # write here\n",
    "            \n",
    "            actions, rewards, terminals = [], [],[]\n",
    "            \n",
    "            for i in range(self.batch_size):\n",
    "                state, action, reward, next_state, terminal = mini_batch[i]\n",
    "                update_input[i] = state\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                update_output[i] = next_state\n",
    "                terminals.append(terminal)\n",
    "                \n",
    "            # Write your code from here\n",
    "            # 1. Predict the target from earlier model\n",
    "            target = self.model.predict(update_input)\n",
    "             \n",
    "            # 2. Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "                \n",
    "            #3. Update your 'update_output' and 'update_input' batch\n",
    "            for i in range(self.batch_size):                \n",
    "                if terminals[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "                \n",
    "                \n",
    "            # 4. Fit your model and track the loss values\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0) \n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)    \n",
    "        \n",
    "   \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episodes = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  environment\n",
    "env = CabDriver()\n",
    "\n",
    "# get size of state and action from environment\n",
    "state_size = len(env.state_space[0])  # equal to 4 in case of cartpole \n",
    "action_size = len(env.action_space)            # equal to 2 in case of cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward -464.0, memory_length 134, epsilon 0.99\n",
      "episode 1, reward -609.0, memory_length 289, epsilon 0.9801\n",
      "episode 2, reward -757.0, memory_length 430, epsilon 0.9702989999999999\n",
      "episode 3, reward -1040.0, memory_length 571, epsilon 0.96059601\n",
      "episode 4, reward -513.0, memory_length 722, epsilon 0.9509900498999999\n",
      "episode 5, reward -378.0, memory_length 868, epsilon 0.9414801494009999\n",
      "episode 6, reward -468.0, memory_length 1014, epsilon 0.9320653479069899\n",
      "episode 7, reward -297.0, memory_length 1160, epsilon 0.92274469442792\n",
      "episode 8, reward -315.0, memory_length 1298, epsilon 0.9135172474836407\n",
      "episode 9, reward -169.0, memory_length 1449, epsilon 0.9043820750088043\n",
      "episode 10, reward -432.0, memory_length 1578, epsilon 0.8953382542587163\n",
      "episode 11, reward -405.0, memory_length 1730, epsilon 0.8863848717161291\n",
      "episode 12, reward -645.0, memory_length 1862, epsilon 0.8775210229989678\n",
      "episode 13, reward -286.0, memory_length 1998, epsilon 0.8687458127689781\n",
      "episode 14, reward -252.0, memory_length 2000, epsilon 0.8600583546412883\n",
      "episode 15, reward -324.0, memory_length 2000, epsilon 0.8514577710948754\n",
      "episode 16, reward -234.0, memory_length 2000, epsilon 0.8429431933839266\n",
      "episode 17, reward -367.0, memory_length 2000, epsilon 0.8345137614500874\n",
      "episode 18, reward -747.0, memory_length 2000, epsilon 0.8261686238355865\n",
      "episode 19, reward -419.0, memory_length 2000, epsilon 0.8179069375972307\n",
      "episode 20, reward -183.0, memory_length 2000, epsilon 0.8097278682212583\n",
      "episode 21, reward -435.0, memory_length 2000, epsilon 0.8016305895390458\n",
      "episode 22, reward -425.0, memory_length 2000, epsilon 0.7936142836436553\n",
      "episode 23, reward -473.0, memory_length 2000, epsilon 0.7856781408072188\n",
      "episode 24, reward -635.0, memory_length 2000, epsilon 0.7778213593991465\n",
      "episode 25, reward -306.0, memory_length 2000, epsilon 0.7700431458051551\n",
      "episode 26, reward -689.0, memory_length 2000, epsilon 0.7623427143471035\n",
      "episode 27, reward -59.0, memory_length 2000, epsilon 0.7547192872036325\n",
      "episode 28, reward -403.0, memory_length 2000, epsilon 0.7471720943315961\n",
      "episode 29, reward -420.0, memory_length 2000, epsilon 0.7397003733882802\n",
      "episode 30, reward -396.0, memory_length 2000, epsilon 0.7323033696543974\n",
      "episode 31, reward -321.0, memory_length 2000, epsilon 0.7249803359578534\n",
      "episode 32, reward -198.0, memory_length 2000, epsilon 0.7177305325982748\n",
      "episode 33, reward -378.0, memory_length 2000, epsilon 0.7105532272722921\n",
      "episode 34, reward -419.0, memory_length 2000, epsilon 0.7034476949995692\n",
      "episode 35, reward -491.0, memory_length 2000, epsilon 0.6964132180495735\n",
      "episode 36, reward -244.0, memory_length 2000, epsilon 0.6894490858690777\n",
      "episode 37, reward -447.0, memory_length 2000, epsilon 0.682554595010387\n",
      "episode 38, reward -171.0, memory_length 2000, epsilon 0.6757290490602831\n",
      "episode 39, reward -359.0, memory_length 2000, epsilon 0.6689717585696803\n",
      "episode 40, reward -216.0, memory_length 2000, epsilon 0.6622820409839835\n",
      "episode 41, reward 26.0, memory_length 2000, epsilon 0.6556592205741436\n",
      "episode 42, reward -356.0, memory_length 2000, epsilon 0.6491026283684022\n",
      "episode 43, reward -50.0, memory_length 2000, epsilon 0.6426116020847181\n",
      "episode 44, reward -260.0, memory_length 2000, epsilon 0.6361854860638709\n",
      "episode 45, reward -583.0, memory_length 2000, epsilon 0.6298236312032323\n",
      "episode 46, reward -293.0, memory_length 2000, epsilon 0.6235253948912\n",
      "episode 47, reward -105.0, memory_length 2000, epsilon 0.617290140942288\n",
      "episode 48, reward -295.0, memory_length 2000, epsilon 0.6111172395328651\n",
      "episode 49, reward -179.0, memory_length 2000, epsilon 0.6050060671375365\n",
      "episode 50, reward -657.0, memory_length 2000, epsilon 0.5989560064661611\n",
      "episode 51, reward 20.0, memory_length 2000, epsilon 0.5929664464014994\n",
      "episode 52, reward -72.0, memory_length 2000, epsilon 0.5870367819374844\n",
      "episode 53, reward -447.0, memory_length 2000, epsilon 0.5811664141181095\n",
      "episode 54, reward -321.0, memory_length 2000, epsilon 0.5753547499769285\n",
      "episode 55, reward -397.0, memory_length 2000, epsilon 0.5696012024771592\n",
      "episode 56, reward -234.0, memory_length 2000, epsilon 0.5639051904523876\n",
      "episode 57, reward -396.0, memory_length 2000, epsilon 0.5582661385478638\n",
      "episode 58, reward -676.0, memory_length 2000, epsilon 0.5526834771623851\n",
      "episode 59, reward -383.0, memory_length 2000, epsilon 0.5471566423907612\n",
      "episode 60, reward -378.0, memory_length 2000, epsilon 0.5416850759668536\n",
      "episode 61, reward -243.0, memory_length 2000, epsilon 0.536268225207185\n",
      "episode 62, reward 26.0, memory_length 2000, epsilon 0.5309055429551132\n",
      "episode 63, reward -339.0, memory_length 2000, epsilon 0.525596487525562\n",
      "episode 64, reward -366.0, memory_length 2000, epsilon 0.5203405226503064\n",
      "episode 65, reward -109.0, memory_length 2000, epsilon 0.5151371174238033\n",
      "episode 66, reward -216.0, memory_length 2000, epsilon 0.5099857462495653\n",
      "episode 67, reward -411.0, memory_length 2000, epsilon 0.5048858887870696\n",
      "episode 68, reward -602.0, memory_length 2000, epsilon 0.4998370298991989\n",
      "episode 69, reward -595.0, memory_length 2000, epsilon 0.49483865960020695\n",
      "episode 70, reward -167.0, memory_length 2000, epsilon 0.4898902730042049\n",
      "episode 71, reward -343.0, memory_length 2000, epsilon 0.48499137027416284\n",
      "episode 72, reward -432.0, memory_length 2000, epsilon 0.4801414565714212\n",
      "episode 73, reward -605.0, memory_length 2000, epsilon 0.475340042005707\n",
      "episode 74, reward -177.0, memory_length 2000, epsilon 0.47058664158564995\n",
      "episode 75, reward -431.0, memory_length 2000, epsilon 0.4658807751697934\n",
      "episode 76, reward -189.0, memory_length 2000, epsilon 0.4612219674180955\n",
      "episode 77, reward -203.0, memory_length 2000, epsilon 0.45660974774391455\n",
      "episode 78, reward -78.0, memory_length 2000, epsilon 0.4520436502664754\n",
      "episode 79, reward -149.0, memory_length 2000, epsilon 0.44752321376381066\n",
      "episode 80, reward -339.0, memory_length 2000, epsilon 0.44304798162617254\n",
      "episode 81, reward -538.0, memory_length 2000, epsilon 0.4386175018099108\n",
      "episode 82, reward -324.0, memory_length 2000, epsilon 0.4342313267918117\n",
      "episode 83, reward -837.0, memory_length 2000, epsilon 0.4298890135238936\n",
      "episode 84, reward -504.0, memory_length 2000, epsilon 0.42559012338865465\n",
      "episode 85, reward -603.0, memory_length 2000, epsilon 0.4213342221547681\n",
      "episode 86, reward -288.0, memory_length 2000, epsilon 0.41712087993322045\n",
      "episode 87, reward -127.0, memory_length 2000, epsilon 0.41294967113388825\n",
      "episode 88, reward -149.0, memory_length 2000, epsilon 0.40882017442254937\n",
      "episode 89, reward -475.0, memory_length 2000, epsilon 0.4047319726783239\n",
      "episode 90, reward -351.0, memory_length 2000, epsilon 0.40068465295154065\n",
      "episode 91, reward -183.0, memory_length 2000, epsilon 0.39667780642202527\n",
      "episode 92, reward 178.0, memory_length 2000, epsilon 0.392711028357805\n",
      "episode 93, reward -117.0, memory_length 2000, epsilon 0.38878391807422696\n",
      "episode 94, reward -378.0, memory_length 2000, epsilon 0.3848960788934847\n",
      "episode 95, reward -109.0, memory_length 2000, epsilon 0.38104711810454983\n",
      "episode 96, reward -162.0, memory_length 2000, epsilon 0.37723664692350434\n",
      "episode 97, reward -599.0, memory_length 2000, epsilon 0.37346428045426927\n",
      "episode 98, reward -113.0, memory_length 2000, epsilon 0.36972963764972655\n",
      "episode 99, reward -343.0, memory_length 2000, epsilon 0.36603234127322926\n",
      "episode 100, reward -231.0, memory_length 2000, epsilon 0.36237201786049694\n",
      "episode 101, reward -23.0, memory_length 2000, epsilon 0.358748297681892\n",
      "episode 102, reward -261.0, memory_length 2000, epsilon 0.35516081470507305\n",
      "episode 103, reward -500.0, memory_length 2000, epsilon 0.3516092065580223\n",
      "episode 104, reward -532.0, memory_length 2000, epsilon 0.34809311449244207\n",
      "episode 105, reward -77.0, memory_length 2000, epsilon 0.34461218334751764\n",
      "episode 106, reward -252.0, memory_length 2000, epsilon 0.34116606151404244\n",
      "episode 107, reward 4.0, memory_length 2000, epsilon 0.337754400898902\n",
      "episode 108, reward -129.0, memory_length 2000, epsilon 0.334376856889913\n",
      "episode 109, reward -221.0, memory_length 2000, epsilon 0.33103308832101386\n",
      "episode 110, reward -221.0, memory_length 2000, epsilon 0.3277227574378037\n",
      "episode 111, reward -671.0, memory_length 2000, epsilon 0.3244455298634257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 112, reward -208.0, memory_length 2000, epsilon 0.3212010745647914\n",
      "episode 113, reward -311.0, memory_length 2000, epsilon 0.3179890638191435\n",
      "episode 114, reward -37.0, memory_length 2000, epsilon 0.31480917318095203\n",
      "episode 115, reward -316.0, memory_length 2000, epsilon 0.3116610814491425\n",
      "episode 116, reward 54.0, memory_length 2000, epsilon 0.30854447063465107\n",
      "episode 117, reward -162.0, memory_length 2000, epsilon 0.30545902592830454\n",
      "episode 118, reward -554.0, memory_length 2000, epsilon 0.3024044356690215\n",
      "episode 119, reward 42.0, memory_length 2000, epsilon 0.29938039131233124\n",
      "episode 120, reward -486.0, memory_length 2000, epsilon 0.2963865873992079\n",
      "episode 121, reward -317.0, memory_length 2000, epsilon 0.29342272152521587\n",
      "episode 122, reward -468.0, memory_length 2000, epsilon 0.2904884943099637\n",
      "episode 123, reward -346.0, memory_length 2000, epsilon 0.28758360936686406\n",
      "episode 124, reward -293.0, memory_length 2000, epsilon 0.2847077732731954\n",
      "episode 125, reward -37.0, memory_length 2000, epsilon 0.28186069554046345\n",
      "episode 126, reward -329.0, memory_length 2000, epsilon 0.2790420885850588\n",
      "episode 127, reward -368.0, memory_length 2000, epsilon 0.2762516676992082\n",
      "episode 128, reward -285.0, memory_length 2000, epsilon 0.27348915102221616\n",
      "episode 129, reward -61.0, memory_length 2000, epsilon 0.270754259511994\n",
      "episode 130, reward -221.0, memory_length 2000, epsilon 0.26804671691687404\n",
      "episode 131, reward -243.0, memory_length 2000, epsilon 0.2653662497477053\n",
      "episode 132, reward -49.0, memory_length 2000, epsilon 0.2627125872502282\n",
      "episode 133, reward -239.0, memory_length 2000, epsilon 0.2600854613777259\n",
      "episode 134, reward -369.0, memory_length 2000, epsilon 0.2574846067639487\n",
      "episode 135, reward -414.0, memory_length 2000, epsilon 0.2549097606963092\n",
      "episode 136, reward 63.0, memory_length 2000, epsilon 0.2523606630893461\n",
      "episode 137, reward -322.0, memory_length 2000, epsilon 0.24983705645845267\n",
      "episode 138, reward -410.0, memory_length 2000, epsilon 0.24733868589386815\n",
      "episode 139, reward -234.0, memory_length 2000, epsilon 0.24486529903492946\n",
      "episode 140, reward -102.0, memory_length 2000, epsilon 0.24241664604458016\n",
      "episode 141, reward -168.0, memory_length 2000, epsilon 0.23999247958413436\n",
      "episode 142, reward -320.0, memory_length 2000, epsilon 0.23759255478829303\n",
      "episode 143, reward 72.0, memory_length 2000, epsilon 0.2352166292404101\n",
      "episode 144, reward -340.0, memory_length 2000, epsilon 0.232864462948006\n",
      "episode 145, reward -65.0, memory_length 2000, epsilon 0.23053581831852593\n",
      "episode 146, reward -313.0, memory_length 2000, epsilon 0.22823046013534068\n",
      "episode 147, reward -40.0, memory_length 2000, epsilon 0.22594815553398728\n",
      "episode 148, reward -163.0, memory_length 2000, epsilon 0.22368867397864742\n",
      "episode 149, reward -522.0, memory_length 2000, epsilon 0.22145178723886094\n",
      "episode 150, reward -360.0, memory_length 2000, epsilon 0.21923726936647234\n",
      "episode 151, reward -42.0, memory_length 2000, epsilon 0.2170448966728076\n",
      "episode 152, reward -14.0, memory_length 2000, epsilon 0.21487444770607952\n",
      "episode 153, reward -338.0, memory_length 2000, epsilon 0.21272570322901874\n",
      "episode 154, reward -56.0, memory_length 2000, epsilon 0.21059844619672854\n",
      "episode 155, reward -89.0, memory_length 2000, epsilon 0.20849246173476127\n",
      "episode 156, reward 30.0, memory_length 2000, epsilon 0.20640753711741366\n",
      "episode 157, reward -406.0, memory_length 2000, epsilon 0.20434346174623952\n",
      "episode 158, reward -406.0, memory_length 2000, epsilon 0.20230002712877712\n",
      "episode 159, reward -262.0, memory_length 2000, epsilon 0.20027702685748935\n",
      "episode 160, reward -249.0, memory_length 2000, epsilon 0.19827425658891445\n",
      "episode 161, reward -419.0, memory_length 2000, epsilon 0.1962915140230253\n",
      "episode 162, reward -162.0, memory_length 2000, epsilon 0.19432859888279505\n",
      "episode 163, reward -261.0, memory_length 2000, epsilon 0.1923853128939671\n",
      "episode 164, reward 117.0, memory_length 2000, epsilon 0.19046145976502743\n",
      "episode 165, reward -117.0, memory_length 2000, epsilon 0.18855684516737714\n",
      "episode 166, reward -352.0, memory_length 2000, epsilon 0.18667127671570335\n",
      "episode 167, reward -83.0, memory_length 2000, epsilon 0.18480456394854633\n",
      "episode 168, reward 31.0, memory_length 2000, epsilon 0.18295651830906087\n",
      "episode 169, reward -288.0, memory_length 2000, epsilon 0.18112695312597027\n",
      "episode 170, reward -70.0, memory_length 2000, epsilon 0.17931568359471056\n",
      "episode 171, reward -62.0, memory_length 2000, epsilon 0.17752252675876345\n",
      "episode 172, reward -149.0, memory_length 2000, epsilon 0.17574730149117582\n",
      "episode 173, reward -496.0, memory_length 2000, epsilon 0.17398982847626407\n",
      "episode 174, reward -118.0, memory_length 2000, epsilon 0.17224993019150142\n",
      "episode 175, reward -90.0, memory_length 2000, epsilon 0.1705274308895864\n",
      "episode 176, reward -213.0, memory_length 2000, epsilon 0.16882215658069055\n",
      "episode 177, reward -320.0, memory_length 2000, epsilon 0.16713393501488363\n",
      "episode 178, reward -32.0, memory_length 2000, epsilon 0.16546259566473479\n",
      "episode 179, reward -226.0, memory_length 2000, epsilon 0.16380796970808745\n",
      "episode 180, reward -129.0, memory_length 2000, epsilon 0.16216989001100657\n",
      "episode 181, reward -144.0, memory_length 2000, epsilon 0.1605481911108965\n",
      "episode 182, reward -205.0, memory_length 2000, epsilon 0.15894270919978754\n",
      "episode 183, reward -214.0, memory_length 2000, epsilon 0.15735328210778965\n",
      "episode 184, reward 6.0, memory_length 2000, epsilon 0.15577974928671176\n",
      "episode 185, reward -262.0, memory_length 2000, epsilon 0.15422195179384465\n",
      "episode 186, reward -248.0, memory_length 2000, epsilon 0.1526797322759062\n",
      "episode 187, reward -573.0, memory_length 2000, epsilon 0.15115293495314713\n",
      "episode 188, reward -333.0, memory_length 2000, epsilon 0.14964140560361566\n",
      "episode 189, reward -351.0, memory_length 2000, epsilon 0.1481449915475795\n",
      "episode 190, reward -61.0, memory_length 2000, epsilon 0.1466635416321037\n",
      "episode 191, reward -298.0, memory_length 2000, epsilon 0.14519690621578268\n",
      "episode 192, reward -239.0, memory_length 2000, epsilon 0.14374493715362485\n",
      "episode 193, reward 54.0, memory_length 2000, epsilon 0.1423074877820886\n",
      "episode 194, reward -163.0, memory_length 2000, epsilon 0.1408844129042677\n",
      "episode 195, reward -82.0, memory_length 2000, epsilon 0.13947556877522502\n",
      "episode 196, reward -15.0, memory_length 2000, epsilon 0.13808081308747278\n",
      "episode 197, reward -131.0, memory_length 2000, epsilon 0.13670000495659804\n",
      "episode 198, reward -168.0, memory_length 2000, epsilon 0.13533300490703207\n",
      "episode 199, reward -117.0, memory_length 2000, epsilon 0.13397967485796175\n",
      "episode 200, reward 38.0, memory_length 2000, epsilon 0.13263987810938213\n",
      "episode 201, reward -41.0, memory_length 2000, epsilon 0.1313134793282883\n",
      "episode 202, reward -5.0, memory_length 2000, epsilon 0.13000034453500542\n",
      "episode 203, reward -1.0, memory_length 2000, epsilon 0.12870034108965536\n",
      "episode 204, reward -77.0, memory_length 2000, epsilon 0.12741333767875881\n",
      "episode 205, reward -162.0, memory_length 2000, epsilon 0.12613920430197123\n",
      "episode 206, reward -302.0, memory_length 2000, epsilon 0.12487781225895152\n",
      "episode 207, reward 47.0, memory_length 2000, epsilon 0.123629034136362\n",
      "episode 208, reward -77.0, memory_length 2000, epsilon 0.12239274379499838\n",
      "episode 209, reward -369.0, memory_length 2000, epsilon 0.1211688163570484\n",
      "episode 210, reward -50.0, memory_length 2000, epsilon 0.11995712819347792\n",
      "episode 211, reward -131.0, memory_length 2000, epsilon 0.11875755691154315\n",
      "episode 212, reward -214.0, memory_length 2000, epsilon 0.11756998134242772\n",
      "episode 213, reward -221.0, memory_length 2000, epsilon 0.11639428152900344\n",
      "episode 214, reward -140.0, memory_length 2000, epsilon 0.11523033871371341\n",
      "episode 215, reward -180.0, memory_length 2000, epsilon 0.11407803532657627\n",
      "episode 216, reward -230.0, memory_length 2000, epsilon 0.11293725497331052\n",
      "episode 217, reward -333.0, memory_length 2000, epsilon 0.1118078824235774\n",
      "episode 218, reward -285.0, memory_length 2000, epsilon 0.11068980359934164\n",
      "episode 219, reward -217.0, memory_length 2000, epsilon 0.10958290556334822\n",
      "episode 220, reward -184.0, memory_length 2000, epsilon 0.10848707650771475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 221, reward -217.0, memory_length 2000, epsilon 0.1074022057426376\n",
      "episode 222, reward -149.0, memory_length 2000, epsilon 0.10632818368521123\n",
      "episode 223, reward 76.0, memory_length 2000, epsilon 0.10526490184835911\n",
      "episode 224, reward -50.0, memory_length 2000, epsilon 0.10421225282987552\n",
      "episode 225, reward -108.0, memory_length 2000, epsilon 0.10317013030157676\n",
      "episode 226, reward -42.0, memory_length 2000, epsilon 0.10213842899856099\n",
      "episode 227, reward -158.0, memory_length 2000, epsilon 0.10111704470857538\n",
      "episode 228, reward -108.0, memory_length 2000, epsilon 0.10010587426148963\n",
      "episode 229, reward -266.0, memory_length 2000, epsilon 0.09910481551887473\n",
      "episode 230, reward -212.0, memory_length 2000, epsilon 0.09811376736368599\n",
      "episode 231, reward 108.0, memory_length 2000, epsilon 0.09713262969004913\n",
      "episode 232, reward -162.0, memory_length 2000, epsilon 0.09616130339314863\n",
      "episode 233, reward -18.0, memory_length 2000, epsilon 0.09519969035921715\n",
      "episode 234, reward 85.0, memory_length 2000, epsilon 0.09424769345562498\n",
      "episode 235, reward -9.0, memory_length 2000, epsilon 0.09330521652106873\n",
      "episode 236, reward -151.0, memory_length 2000, epsilon 0.09237216435585804\n",
      "episode 237, reward -69.0, memory_length 2000, epsilon 0.09144844271229946\n",
      "episode 238, reward 38.0, memory_length 2000, epsilon 0.09053395828517646\n",
      "episode 239, reward -105.0, memory_length 2000, epsilon 0.08962861870232469\n",
      "episode 240, reward -410.0, memory_length 2000, epsilon 0.08873233251530144\n",
      "episode 241, reward -38.0, memory_length 2000, epsilon 0.08784500919014843\n",
      "episode 242, reward -104.0, memory_length 2000, epsilon 0.08696655909824694\n",
      "episode 243, reward -110.0, memory_length 2000, epsilon 0.08609689350726446\n",
      "episode 244, reward -420.0, memory_length 2000, epsilon 0.08523592457219181\n",
      "episode 245, reward -151.0, memory_length 2000, epsilon 0.0843835653264699\n",
      "episode 246, reward 156.0, memory_length 2000, epsilon 0.0835397296732052\n",
      "episode 247, reward -9.0, memory_length 2000, epsilon 0.08270433237647315\n",
      "episode 248, reward 58.0, memory_length 2000, epsilon 0.08187728905270841\n",
      "episode 249, reward -235.0, memory_length 2000, epsilon 0.08105851616218133\n",
      "episode 250, reward -207.0, memory_length 2000, epsilon 0.08024793100055952\n",
      "episode 251, reward -27.0, memory_length 2000, epsilon 0.07944545169055392\n",
      "episode 252, reward -135.0, memory_length 2000, epsilon 0.07865099717364837\n",
      "episode 253, reward -102.0, memory_length 2000, epsilon 0.07786448720191189\n",
      "episode 254, reward -172.0, memory_length 2000, epsilon 0.07708584232989277\n",
      "episode 255, reward -99.0, memory_length 2000, epsilon 0.07631498390659384\n",
      "episode 256, reward -131.0, memory_length 2000, epsilon 0.07555183406752791\n",
      "episode 257, reward -53.0, memory_length 2000, epsilon 0.07479631572685264\n",
      "episode 258, reward -262.0, memory_length 2000, epsilon 0.07404835256958411\n",
      "episode 259, reward -225.0, memory_length 2000, epsilon 0.07330786904388827\n",
      "episode 260, reward 38.0, memory_length 2000, epsilon 0.07257479035344938\n",
      "episode 261, reward -315.0, memory_length 2000, epsilon 0.07184904244991488\n",
      "episode 262, reward -108.0, memory_length 2000, epsilon 0.07113055202541574\n",
      "episode 263, reward -210.0, memory_length 2000, epsilon 0.07041924650516158\n",
      "episode 264, reward 26.0, memory_length 2000, epsilon 0.06971505404010997\n",
      "episode 265, reward -67.0, memory_length 2000, epsilon 0.06901790349970886\n",
      "episode 266, reward -90.0, memory_length 2000, epsilon 0.06832772446471178\n",
      "episode 267, reward 34.0, memory_length 2000, epsilon 0.06764444722006466\n",
      "episode 268, reward 47.0, memory_length 2000, epsilon 0.066968002747864\n",
      "episode 269, reward -77.0, memory_length 2000, epsilon 0.06629832272038537\n",
      "episode 270, reward -266.0, memory_length 2000, epsilon 0.06563533949318151\n",
      "episode 271, reward -180.0, memory_length 2000, epsilon 0.06497898609824969\n",
      "episode 272, reward 139.0, memory_length 2000, epsilon 0.0643291962372672\n",
      "episode 273, reward -293.0, memory_length 2000, epsilon 0.06368590427489453\n",
      "episode 274, reward -468.0, memory_length 2000, epsilon 0.06304904523214558\n",
      "episode 275, reward 179.0, memory_length 2000, epsilon 0.06241855477982412\n",
      "episode 276, reward -64.0, memory_length 2000, epsilon 0.06179436923202588\n",
      "episode 277, reward 4.0, memory_length 2000, epsilon 0.06117642553970562\n",
      "episode 278, reward -100.0, memory_length 2000, epsilon 0.06056466128430856\n",
      "episode 279, reward -149.0, memory_length 2000, epsilon 0.05995901467146548\n",
      "episode 280, reward 9.0, memory_length 2000, epsilon 0.05935942452475082\n",
      "episode 281, reward -32.0, memory_length 2000, epsilon 0.058765830279503314\n",
      "episode 282, reward -113.0, memory_length 2000, epsilon 0.05817817197670828\n",
      "episode 283, reward -27.0, memory_length 2000, epsilon 0.057596390256941195\n",
      "episode 284, reward -77.0, memory_length 2000, epsilon 0.05702042635437178\n",
      "episode 285, reward -324.0, memory_length 2000, epsilon 0.05645022209082806\n",
      "episode 286, reward -118.0, memory_length 2000, epsilon 0.05588571986991978\n",
      "episode 287, reward -1.0, memory_length 2000, epsilon 0.055326862671220584\n",
      "episode 288, reward -209.0, memory_length 2000, epsilon 0.05477359404450838\n",
      "episode 289, reward -86.0, memory_length 2000, epsilon 0.054225858104063294\n",
      "episode 290, reward 88.0, memory_length 2000, epsilon 0.05368359952302266\n",
      "episode 291, reward -45.0, memory_length 2000, epsilon 0.053146763527792434\n",
      "episode 292, reward -56.0, memory_length 2000, epsilon 0.052615295892514506\n",
      "episode 293, reward -50.0, memory_length 2000, epsilon 0.052089142933589364\n",
      "episode 294, reward -72.0, memory_length 2000, epsilon 0.05156825150425347\n",
      "episode 295, reward -86.0, memory_length 2000, epsilon 0.051052568989210935\n",
      "episode 296, reward -119.0, memory_length 2000, epsilon 0.05054204329931883\n",
      "episode 297, reward -459.0, memory_length 2000, epsilon 0.05003662286632564\n",
      "episode 298, reward -50.0, memory_length 2000, epsilon 0.04953625663766238\n",
      "episode 299, reward -491.0, memory_length 2000, epsilon 0.04904089407128576\n",
      "episode 300, reward -50.0, memory_length 2000, epsilon 0.0485504851305729\n",
      "episode 301, reward 123.0, memory_length 2000, epsilon 0.048064980279267165\n",
      "episode 302, reward -189.0, memory_length 2000, epsilon 0.04758433047647449\n",
      "episode 303, reward -68.0, memory_length 2000, epsilon 0.04710848717170975\n",
      "episode 304, reward -68.0, memory_length 2000, epsilon 0.04663740229999265\n",
      "episode 305, reward -48.0, memory_length 2000, epsilon 0.04617102827699272\n",
      "episode 306, reward 19.0, memory_length 2000, epsilon 0.045709317994222794\n",
      "episode 307, reward -37.0, memory_length 2000, epsilon 0.04525222481428057\n",
      "episode 308, reward -217.0, memory_length 2000, epsilon 0.04479970256613776\n",
      "episode 309, reward -82.0, memory_length 2000, epsilon 0.04435170554047638\n",
      "episode 310, reward 116.0, memory_length 2000, epsilon 0.043908188485071616\n",
      "episode 311, reward -72.0, memory_length 2000, epsilon 0.0434691066002209\n",
      "episode 312, reward -81.0, memory_length 2000, epsilon 0.04303441553421869\n",
      "episode 313, reward -82.0, memory_length 2000, epsilon 0.0426040713788765\n",
      "episode 314, reward -248.0, memory_length 2000, epsilon 0.04217803066508773\n",
      "episode 315, reward -112.0, memory_length 2000, epsilon 0.04175625035843686\n",
      "episode 316, reward -167.0, memory_length 2000, epsilon 0.041338687854852486\n",
      "episode 317, reward 65.0, memory_length 2000, epsilon 0.04092530097630396\n",
      "episode 318, reward -27.0, memory_length 2000, epsilon 0.040516047966540916\n",
      "episode 319, reward 273.0, memory_length 2000, epsilon 0.04011088748687551\n",
      "episode 320, reward -18.0, memory_length 2000, epsilon 0.03970977861200675\n",
      "episode 321, reward 72.0, memory_length 2000, epsilon 0.03931268082588668\n",
      "episode 322, reward -9.0, memory_length 2000, epsilon 0.03891955401762781\n",
      "episode 323, reward -81.0, memory_length 2000, epsilon 0.03853035847745153\n",
      "episode 324, reward -2.0, memory_length 2000, epsilon 0.03814505489267701\n",
      "episode 325, reward -204.0, memory_length 2000, epsilon 0.03776360434375024\n",
      "episode 326, reward -158.0, memory_length 2000, epsilon 0.03738596830031274\n",
      "episode 327, reward -248.0, memory_length 2000, epsilon 0.03701210861730961\n",
      "episode 328, reward -135.0, memory_length 2000, epsilon 0.03664198753113651\n",
      "episode 329, reward -2.0, memory_length 2000, epsilon 0.036275567655825146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 330, reward -613.0, memory_length 2000, epsilon 0.03591281197926689\n",
      "episode 331, reward -374.0, memory_length 2000, epsilon 0.035553683859474224\n",
      "episode 332, reward -243.0, memory_length 2000, epsilon 0.03519814702087948\n",
      "episode 333, reward -194.0, memory_length 2000, epsilon 0.03484616555067068\n",
      "episode 334, reward -271.0, memory_length 2000, epsilon 0.034497703895163975\n",
      "episode 335, reward -77.0, memory_length 2000, epsilon 0.03415272685621234\n",
      "episode 336, reward -209.0, memory_length 2000, epsilon 0.03381119958765021\n",
      "episode 337, reward -145.0, memory_length 2000, epsilon 0.03347308759177371\n",
      "episode 338, reward -118.0, memory_length 2000, epsilon 0.03313835671585597\n",
      "episode 339, reward -46.0, memory_length 2000, epsilon 0.03280697314869741\n",
      "episode 340, reward -104.0, memory_length 2000, epsilon 0.032478903417210436\n",
      "episode 341, reward -149.0, memory_length 2000, epsilon 0.032154114383038335\n",
      "episode 342, reward -186.0, memory_length 2000, epsilon 0.03183257323920795\n",
      "episode 343, reward -130.0, memory_length 2000, epsilon 0.03151424750681587\n",
      "episode 344, reward 35.0, memory_length 2000, epsilon 0.03119910503174771\n",
      "episode 345, reward 188.0, memory_length 2000, epsilon 0.030887113981430233\n",
      "episode 346, reward -108.0, memory_length 2000, epsilon 0.03057824284161593\n",
      "episode 347, reward -212.0, memory_length 2000, epsilon 0.03027246041319977\n",
      "episode 348, reward 139.0, memory_length 2000, epsilon 0.029969735809067772\n",
      "episode 349, reward -235.0, memory_length 2000, epsilon 0.029670038450977095\n",
      "episode 350, reward -167.0, memory_length 2000, epsilon 0.029373338066467324\n",
      "episode 351, reward -111.0, memory_length 2000, epsilon 0.02907960468580265\n",
      "episode 352, reward -33.0, memory_length 2000, epsilon 0.028788808638944622\n",
      "episode 353, reward -185.0, memory_length 2000, epsilon 0.028500920552555174\n",
      "episode 354, reward 9.0, memory_length 2000, epsilon 0.028215911347029624\n",
      "episode 355, reward -152.0, memory_length 2000, epsilon 0.027933752233559327\n",
      "episode 356, reward -91.0, memory_length 2000, epsilon 0.027654414711223735\n",
      "episode 357, reward -461.0, memory_length 2000, epsilon 0.027377870564111496\n",
      "episode 358, reward -288.0, memory_length 2000, epsilon 0.027104091858470382\n",
      "episode 359, reward -41.0, memory_length 2000, epsilon 0.026833050939885677\n",
      "episode 360, reward -271.0, memory_length 2000, epsilon 0.02656472043048682\n",
      "episode 361, reward -113.0, memory_length 2000, epsilon 0.02629907322618195\n",
      "episode 362, reward -105.0, memory_length 2000, epsilon 0.026036082493920133\n",
      "episode 363, reward -410.0, memory_length 2000, epsilon 0.02577572166898093\n",
      "episode 364, reward 52.0, memory_length 2000, epsilon 0.025517964452291122\n",
      "episode 365, reward 319.0, memory_length 2000, epsilon 0.02526278480776821\n",
      "episode 366, reward -174.0, memory_length 2000, epsilon 0.025010156959690527\n",
      "episode 367, reward 9.0, memory_length 2000, epsilon 0.02476005539009362\n",
      "episode 368, reward -146.0, memory_length 2000, epsilon 0.024512454836192684\n",
      "episode 369, reward -244.0, memory_length 2000, epsilon 0.024267330287830756\n",
      "episode 370, reward -29.0, memory_length 2000, epsilon 0.024024656984952448\n",
      "episode 371, reward -81.0, memory_length 2000, epsilon 0.023784410415102923\n",
      "episode 372, reward -68.0, memory_length 2000, epsilon 0.023546566310951894\n",
      "episode 373, reward -234.0, memory_length 2000, epsilon 0.023311100647842375\n",
      "episode 374, reward -54.0, memory_length 2000, epsilon 0.02307798964136395\n",
      "episode 375, reward -108.0, memory_length 2000, epsilon 0.022847209744950314\n",
      "episode 376, reward -28.0, memory_length 2000, epsilon 0.02261873764750081\n",
      "episode 377, reward -86.0, memory_length 2000, epsilon 0.022392550271025803\n",
      "episode 378, reward 90.0, memory_length 2000, epsilon 0.022168624768315544\n",
      "episode 379, reward 103.0, memory_length 2000, epsilon 0.02194693852063239\n",
      "episode 380, reward 62.0, memory_length 2000, epsilon 0.021727469135426065\n",
      "episode 381, reward -69.0, memory_length 2000, epsilon 0.021510194444071803\n",
      "episode 382, reward -99.0, memory_length 2000, epsilon 0.021295092499631085\n",
      "episode 383, reward -16.0, memory_length 2000, epsilon 0.021082141574634772\n",
      "episode 384, reward 243.0, memory_length 2000, epsilon 0.020871320158888425\n",
      "episode 385, reward -2.0, memory_length 2000, epsilon 0.020662606957299542\n",
      "episode 386, reward -264.0, memory_length 2000, epsilon 0.020455980887726547\n",
      "episode 387, reward -330.0, memory_length 2000, epsilon 0.02025142107884928\n",
      "episode 388, reward -264.0, memory_length 2000, epsilon 0.020048906868060788\n",
      "episode 389, reward -270.0, memory_length 2000, epsilon 0.01984841779938018\n",
      "episode 390, reward -187.0, memory_length 2000, epsilon 0.019649933621386378\n",
      "episode 391, reward -55.0, memory_length 2000, epsilon 0.019453434285172513\n",
      "episode 392, reward 57.0, memory_length 2000, epsilon 0.019258899942320787\n",
      "episode 393, reward -39.0, memory_length 2000, epsilon 0.01906631094289758\n",
      "episode 394, reward -288.0, memory_length 2000, epsilon 0.018875647833468602\n",
      "episode 395, reward 61.0, memory_length 2000, epsilon 0.018686891355133916\n",
      "episode 396, reward -146.0, memory_length 2000, epsilon 0.018500022441582577\n",
      "episode 397, reward -142.0, memory_length 2000, epsilon 0.01831502221716675\n",
      "episode 398, reward -61.0, memory_length 2000, epsilon 0.018131871994995084\n",
      "episode 399, reward -271.0, memory_length 2000, epsilon 0.017950553275045134\n",
      "episode 400, reward 81.0, memory_length 2000, epsilon 0.017771047742294682\n",
      "episode 401, reward -2.0, memory_length 2000, epsilon 0.017593337264871736\n",
      "episode 402, reward -14.0, memory_length 2000, epsilon 0.01741740389222302\n",
      "episode 403, reward -23.0, memory_length 2000, epsilon 0.01724322985330079\n",
      "episode 404, reward -60.0, memory_length 2000, epsilon 0.017070797554767782\n",
      "episode 405, reward -12.0, memory_length 2000, epsilon 0.016900089579220106\n",
      "episode 406, reward 10.0, memory_length 2000, epsilon 0.016731088683427906\n",
      "episode 407, reward -294.0, memory_length 2000, epsilon 0.016563777796593626\n",
      "episode 408, reward 58.0, memory_length 2000, epsilon 0.016398140018627688\n",
      "episode 409, reward -7.0, memory_length 2000, epsilon 0.01623415861844141\n",
      "episode 410, reward -185.0, memory_length 2000, epsilon 0.016071817032256998\n",
      "episode 411, reward -33.0, memory_length 2000, epsilon 0.01591109886193443\n",
      "episode 412, reward -149.0, memory_length 2000, epsilon 0.015751987873315085\n",
      "episode 413, reward 200.0, memory_length 2000, epsilon 0.015594467994581935\n",
      "episode 414, reward 121.0, memory_length 2000, epsilon 0.015438523314636115\n",
      "episode 415, reward 40.0, memory_length 2000, epsilon 0.015284138081489753\n",
      "episode 416, reward 4.0, memory_length 2000, epsilon 0.015131296700674856\n",
      "episode 417, reward 98.0, memory_length 2000, epsilon 0.014979983733668108\n",
      "episode 418, reward -279.0, memory_length 2000, epsilon 0.014830183896331426\n",
      "episode 419, reward -87.0, memory_length 2000, epsilon 0.014681882057368112\n",
      "episode 420, reward 57.0, memory_length 2000, epsilon 0.01453506323679443\n",
      "episode 421, reward -77.0, memory_length 2000, epsilon 0.014389712604426485\n",
      "episode 422, reward -153.0, memory_length 2000, epsilon 0.01424581547838222\n",
      "episode 423, reward 19.0, memory_length 2000, epsilon 0.014103357323598397\n",
      "episode 424, reward -50.0, memory_length 2000, epsilon 0.013962323750362413\n",
      "episode 425, reward -55.0, memory_length 2000, epsilon 0.013822700512858789\n",
      "episode 426, reward -196.0, memory_length 2000, epsilon 0.0136844735077302\n",
      "episode 427, reward -333.0, memory_length 2000, epsilon 0.013547628772652899\n",
      "episode 428, reward 16.0, memory_length 2000, epsilon 0.01341215248492637\n",
      "episode 429, reward 45.0, memory_length 2000, epsilon 0.013278030960077106\n",
      "episode 430, reward -125.0, memory_length 2000, epsilon 0.013145250650476335\n",
      "episode 431, reward -11.0, memory_length 2000, epsilon 0.01301379814397157\n",
      "episode 432, reward 102.0, memory_length 2000, epsilon 0.012883660162531854\n",
      "episode 433, reward -208.0, memory_length 2000, epsilon 0.012754823560906535\n",
      "episode 434, reward -361.0, memory_length 2000, epsilon 0.01262727532529747\n",
      "episode 435, reward 58.0, memory_length 2000, epsilon 0.012501002572044496\n",
      "episode 436, reward -171.0, memory_length 2000, epsilon 0.01237599254632405\n",
      "episode 437, reward 106.0, memory_length 2000, epsilon 0.01225223262086081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 438, reward 314.0, memory_length 2000, epsilon 0.012129710294652202\n",
      "episode 439, reward -279.0, memory_length 2000, epsilon 0.01200841319170568\n",
      "episode 440, reward 53.0, memory_length 2000, epsilon 0.011888329059788623\n",
      "episode 441, reward -14.0, memory_length 2000, epsilon 0.011769445769190737\n",
      "episode 442, reward -100.0, memory_length 2000, epsilon 0.01165175131149883\n",
      "episode 443, reward 234.0, memory_length 2000, epsilon 0.011535233798383842\n",
      "episode 444, reward -59.0, memory_length 2000, epsilon 0.011419881460400004\n",
      "episode 445, reward -63.0, memory_length 2000, epsilon 0.011305682645796004\n",
      "episode 446, reward -50.0, memory_length 2000, epsilon 0.011192625819338045\n",
      "episode 447, reward -99.0, memory_length 2000, epsilon 0.011080699561144665\n",
      "episode 448, reward -175.0, memory_length 2000, epsilon 0.010969892565533218\n",
      "episode 449, reward 101.0, memory_length 2000, epsilon 0.010860193639877886\n",
      "episode 450, reward -243.0, memory_length 2000, epsilon 0.010751591703479106\n",
      "episode 451, reward -242.0, memory_length 2000, epsilon 0.010644075786444315\n",
      "episode 452, reward -93.0, memory_length 2000, epsilon 0.010537635028579873\n",
      "episode 453, reward -3.0, memory_length 2000, epsilon 0.010432258678294073\n",
      "episode 454, reward -50.0, memory_length 2000, epsilon 0.010327936091511133\n",
      "episode 455, reward -56.0, memory_length 2000, epsilon 0.010224656730596022\n",
      "episode 456, reward 135.0, memory_length 2000, epsilon 0.01012241016329006\n",
      "episode 457, reward 13.0, memory_length 2000, epsilon 0.01002118606165716\n",
      "episode 458, reward 35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 459, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 460, reward 29.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 461, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 462, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 463, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 464, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 465, reward -61.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 466, reward -129.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 467, reward -214.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 468, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 469, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 470, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 471, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 472, reward -106.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 473, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 474, reward -172.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 475, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 476, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 477, reward 159.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 478, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 479, reward -9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 480, reward 121.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 481, reward -163.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 482, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 483, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 484, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 485, reward 155.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 486, reward 151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 487, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 488, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 489, reward -243.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 490, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 491, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 492, reward 23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 493, reward 87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 494, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 495, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 496, reward 188.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 497, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 498, reward -236.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 499, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 500, reward -419.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 501, reward -244.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 502, reward 5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 503, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 504, reward -217.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 505, reward -186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 506, reward 305.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 507, reward 70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 508, reward 211.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 509, reward 126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 510, reward 145.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 511, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 512, reward -35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 513, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 514, reward 192.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 515, reward -151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 516, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 517, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 518, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 519, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 520, reward -72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 521, reward 175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 522, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 523, reward -276.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 524, reward 108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 525, reward 49.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 526, reward -116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 527, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 528, reward -298.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 529, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 530, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 531, reward 62.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 532, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 533, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 534, reward -353.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 535, reward 70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 536, reward 125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 537, reward -145.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 538, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 539, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 540, reward 130.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 541, reward -183.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 542, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 543, reward -222.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 544, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 545, reward 94.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 546, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 547, reward -96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 548, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 549, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 550, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 551, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 552, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 553, reward -301.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 554, reward -199.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 555, reward -194.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 556, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 557, reward -235.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 558, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 559, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 560, reward -230.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 561, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 562, reward -87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 563, reward -123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 564, reward -392.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 565, reward -369.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 566, reward -56.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 567, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 568, reward -111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 569, reward -148.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 570, reward -410.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 571, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 572, reward -115.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 573, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 574, reward -39.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 575, reward -34.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 576, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 577, reward -408.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 578, reward 41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 579, reward 125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 580, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 581, reward 220.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 582, reward -248.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 583, reward -70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 584, reward -72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 585, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 586, reward -132.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 587, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 588, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 589, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 590, reward -87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 591, reward -169.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 592, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 593, reward -82.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 594, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 595, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 596, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 597, reward -163.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 598, reward -128.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 599, reward -107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 600, reward -118.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 601, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 602, reward -342.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 603, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 604, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 605, reward -137.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 606, reward 150.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 607, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 608, reward -228.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 609, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 610, reward -315.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 611, reward 139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 612, reward 93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 613, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 614, reward 180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 615, reward 181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 616, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 617, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 618, reward 175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 619, reward -18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 620, reward -48.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 621, reward -160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 622, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 623, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 624, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 625, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 626, reward -15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 627, reward -105.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 628, reward -224.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 629, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 630, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 631, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 632, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 633, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 634, reward -232.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 635, reward -230.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 636, reward -15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 637, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 638, reward -364.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 639, reward -145.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 640, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 641, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 642, reward -303.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 643, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 644, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 645, reward 90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 646, reward -341.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 647, reward -204.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 648, reward 7.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 649, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 650, reward 175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 651, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 652, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 653, reward 49.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 654, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 655, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 656, reward -2.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 657, reward -182.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 658, reward -15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 659, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 660, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 661, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 662, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 663, reward -173.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 664, reward -87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 665, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 666, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 667, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 668, reward -222.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 669, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 670, reward -230.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 671, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 672, reward -473.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 673, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 674, reward -69.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 675, reward -42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 676, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 677, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 678, reward -11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 679, reward -318.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 680, reward -138.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 681, reward -103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 682, reward -306.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 683, reward -84.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 684, reward 16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 685, reward 66.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 686, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 687, reward 292.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 688, reward -9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 689, reward -38.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 690, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 691, reward -57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 692, reward -204.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 693, reward -262.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 694, reward -16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 695, reward 59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 696, reward -57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 697, reward 189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 698, reward 35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 699, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 700, reward 2.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 701, reward -75.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 702, reward -266.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 703, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 704, reward 151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 705, reward -98.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 706, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 707, reward -150.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 708, reward 46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 709, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 710, reward -97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 711, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 712, reward -97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 713, reward 40.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 714, reward -243.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 715, reward 124.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 716, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 717, reward -125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 718, reward 359.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 719, reward -217.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 720, reward 1.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 721, reward -221.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 722, reward 87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 723, reward -83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 724, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 725, reward -137.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 726, reward -302.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 727, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 728, reward -111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 729, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 730, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 731, reward -133.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 732, reward -430.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 733, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 734, reward -190.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 735, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 736, reward -109.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 737, reward 38.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 738, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 739, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 740, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 741, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 742, reward 25.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 743, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 744, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 745, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 746, reward -208.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 747, reward 126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 748, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 749, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 750, reward 69.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 751, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 752, reward -14.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 753, reward 2.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 754, reward 115.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 755, reward -143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 756, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 757, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 758, reward 135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 759, reward 98.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 760, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 761, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 762, reward -127.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 763, reward 7.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 764, reward -133.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 765, reward -52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 766, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 767, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 768, reward 100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 769, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 770, reward 57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 771, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 772, reward -25.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 773, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 774, reward -118.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 775, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 776, reward -208.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 777, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 778, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 779, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 780, reward 171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 781, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 782, reward 217.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 783, reward 106.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 784, reward -239.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 785, reward 143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 786, reward 170.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 787, reward -179.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 788, reward 102.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 789, reward -316.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 790, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 791, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 792, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 793, reward -94.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 794, reward -9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 795, reward 103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 796, reward -106.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 797, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 798, reward 135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 799, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 800, reward 51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 801, reward 193.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 802, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 803, reward 37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 804, reward 90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 805, reward -139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 806, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 807, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 808, reward -125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 809, reward 95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 810, reward -188.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 811, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 812, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 813, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 814, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 815, reward 40.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 816, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 817, reward -183.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 818, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 819, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 820, reward 49.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 821, reward -35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 822, reward -217.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 823, reward -342.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 824, reward 121.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 825, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 826, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 827, reward -111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 828, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 829, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 830, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 831, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 832, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 833, reward -356.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 834, reward 61.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 835, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 836, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 837, reward 157.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 838, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 839, reward 162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 840, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 841, reward -148.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 842, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 843, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 844, reward 94.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 845, reward -168.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 846, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 847, reward -205.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 848, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 849, reward -49.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 850, reward 306.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 851, reward 62.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 852, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 853, reward -187.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 854, reward 2.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 855, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 856, reward -186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 857, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 858, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 859, reward -204.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 860, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 861, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 862, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 863, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 864, reward -168.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 865, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 866, reward -44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 867, reward 116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 868, reward -3.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 869, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 870, reward -450.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 871, reward -109.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 872, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 873, reward -114.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 874, reward -123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 875, reward -195.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 876, reward 242.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 877, reward -259.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 878, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 879, reward 6.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 880, reward 65.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 881, reward -25.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 882, reward -320.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 883, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 884, reward 143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 885, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 886, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 887, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 888, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 889, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 890, reward -114.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 891, reward 186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 892, reward -65.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 893, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 894, reward -255.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 895, reward -334.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 896, reward -209.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 897, reward -336.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 898, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 899, reward -338.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 900, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 901, reward 100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 902, reward -352.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 903, reward 72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 904, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 905, reward 147.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 906, reward 184.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 907, reward 171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 908, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 909, reward 216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 910, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 911, reward -30.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 912, reward -194.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 913, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 914, reward 251.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 915, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 916, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 917, reward -334.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 918, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 919, reward -295.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 920, reward -366.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 921, reward -168.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 922, reward 233.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 923, reward -192.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 924, reward 201.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 925, reward -120.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 926, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 927, reward 56.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 928, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 929, reward -60.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 930, reward -172.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 931, reward 218.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 932, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 933, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 934, reward 171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 935, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 936, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 937, reward -190.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 938, reward 94.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 939, reward -107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 940, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 941, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 942, reward 123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 943, reward 73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 944, reward -169.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 945, reward -74.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 946, reward -114.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 947, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 948, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 949, reward 161.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 950, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 951, reward -248.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 952, reward -141.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 953, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 954, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 955, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 956, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 957, reward 189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 958, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 959, reward 87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 960, reward -243.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 961, reward -9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 962, reward -42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 963, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 964, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 965, reward 165.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 966, reward 137.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 967, reward 157.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 968, reward -284.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 969, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 970, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 971, reward -174.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 972, reward 11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 973, reward -159.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 974, reward -316.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 975, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 976, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 977, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 978, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 979, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 980, reward 108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 981, reward 157.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 982, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 983, reward 274.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 984, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 985, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 986, reward 44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 987, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 988, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 989, reward -360.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 990, reward -39.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 991, reward 56.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 992, reward -234.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 993, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 994, reward 98.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 995, reward -205.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 996, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 997, reward 55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 998, reward 222.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 999, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1000, reward -172.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1001, reward -329.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1002, reward 84.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1003, reward -218.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1004, reward -281.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1005, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1006, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1007, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1008, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1009, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1010, reward -142.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1011, reward 43.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1012, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1013, reward 199.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1014, reward -143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1015, reward -119.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1016, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1017, reward 219.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1018, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1019, reward 72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1020, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1021, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1022, reward -97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1023, reward -168.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1024, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1025, reward -194.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1026, reward 161.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1027, reward 65.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1028, reward -277.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1029, reward 39.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1030, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1031, reward 70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1032, reward 65.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1033, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1034, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1035, reward 83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1036, reward 49.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1037, reward 164.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1038, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1039, reward 139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1040, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1041, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1042, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1043, reward 213.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1044, reward -147.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1045, reward -146.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1046, reward -477.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1047, reward -18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1048, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1049, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1050, reward 225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1051, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1052, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1053, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1054, reward 112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1055, reward -230.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1056, reward 90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1057, reward -151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1058, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1059, reward 130.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1060, reward 148.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1061, reward 72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1062, reward 16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1063, reward -97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1064, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1065, reward -288.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1066, reward 89.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1067, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1068, reward 111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1069, reward -93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1070, reward -116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1071, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1072, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1073, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1074, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1075, reward -288.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1076, reward -34.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1077, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1078, reward 310.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1079, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1080, reward 52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1081, reward 12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1082, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1083, reward -66.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1084, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1085, reward -52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1086, reward -306.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1087, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1088, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1089, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1090, reward 301.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1091, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1092, reward 84.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1093, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1094, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1095, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1096, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1097, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1098, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1099, reward -235.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1100, reward 124.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1101, reward -262.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1102, reward 215.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1103, reward -128.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1104, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1105, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1106, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1107, reward 24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1108, reward -71.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1109, reward -34.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1110, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1111, reward 39.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1112, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1113, reward -43.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1114, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1115, reward -60.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1116, reward -262.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1117, reward 164.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1118, reward -155.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1119, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1120, reward -123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1121, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1122, reward 44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1123, reward -385.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1124, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1125, reward 112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1126, reward -74.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1127, reward -12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1128, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1129, reward 175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1130, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1131, reward 25.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1132, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1133, reward -12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1134, reward -43.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1135, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1136, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1137, reward -93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1138, reward 26.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1139, reward -284.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1140, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1141, reward 154.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1142, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1143, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1144, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1145, reward -329.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1146, reward -147.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1147, reward -163.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1148, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1149, reward 98.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1150, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1151, reward -105.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1152, reward -74.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1153, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1154, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1155, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1156, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1157, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1158, reward -172.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1159, reward 108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1160, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1161, reward 126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1162, reward 72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1163, reward 154.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1164, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1165, reward 40.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1166, reward -224.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1167, reward -25.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1168, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1169, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1170, reward -127.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1171, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1172, reward -151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1173, reward 74.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1174, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1175, reward -208.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1176, reward -53.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1177, reward 140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1178, reward -357.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1179, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1180, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1181, reward -320.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1182, reward -288.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1183, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1184, reward 180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1185, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1186, reward -243.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1187, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1188, reward 121.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1189, reward -7.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1190, reward 170.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1191, reward -190.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1192, reward 96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1193, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1194, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1195, reward -70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1196, reward 111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1197, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1198, reward -105.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1199, reward -146.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1200, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1201, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1202, reward 157.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1203, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1204, reward -88.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1205, reward -322.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1206, reward -170.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1207, reward 143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1208, reward -253.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1209, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1210, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1211, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1212, reward -297.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1213, reward 89.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1214, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1215, reward -298.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1216, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1217, reward -119.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1218, reward -8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1219, reward 144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1220, reward 198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1221, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1222, reward -221.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1223, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1224, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1225, reward -347.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1226, reward -186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1227, reward -42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1228, reward 93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1229, reward 72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1230, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1231, reward -450.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1232, reward -419.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1233, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1234, reward -15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1235, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1236, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1237, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1238, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1239, reward 52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1240, reward 73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1241, reward -14.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1242, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1243, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1244, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1245, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1246, reward 126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1247, reward -87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1248, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1249, reward 91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1250, reward -253.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1251, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1252, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1253, reward -379.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1254, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1255, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1256, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1257, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1258, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1259, reward 55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1260, reward -199.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1261, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1262, reward 97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1263, reward -101.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1264, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1265, reward -115.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1266, reward -343.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1267, reward -315.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1268, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1269, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1270, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1271, reward -287.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1272, reward -112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1273, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1274, reward -302.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1275, reward -375.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1276, reward 125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1277, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1278, reward -174.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1279, reward 35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1280, reward -57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1281, reward -450.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1282, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1283, reward 29.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1284, reward 246.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1285, reward 103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1286, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1287, reward 175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1288, reward 116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1289, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1290, reward -116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1291, reward -206.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1292, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1293, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1294, reward 69.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1295, reward -60.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1296, reward -396.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1297, reward 15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1298, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1299, reward -43.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1300, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1301, reward 48.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1302, reward -398.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1303, reward -244.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1304, reward -230.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1305, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1306, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1307, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1308, reward -82.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1309, reward 162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1310, reward -239.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1311, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1312, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1313, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1314, reward -208.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1315, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1316, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1317, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1318, reward -312.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1319, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1320, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1321, reward -318.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1322, reward -134.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1323, reward 229.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1324, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1325, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1326, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1327, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1328, reward -17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1329, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1330, reward 42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1331, reward -12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1332, reward -80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1333, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1334, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1335, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1336, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1337, reward 202.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1338, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1339, reward -102.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1340, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1341, reward -61.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1342, reward -254.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1343, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1344, reward -12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1345, reward 61.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1346, reward -141.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1347, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1348, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1349, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1350, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1351, reward -72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1352, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1353, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1354, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1355, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1356, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1357, reward 59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1358, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1359, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1360, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1361, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1362, reward -333.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1363, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1364, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1365, reward -83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1366, reward 283.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1367, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1368, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1369, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1370, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1371, reward 26.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1372, reward -111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1373, reward 40.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1374, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1375, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1376, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1377, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1378, reward -169.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1379, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1380, reward -27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1381, reward 242.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1382, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1383, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1384, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1385, reward 44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1386, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1387, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1388, reward 112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1389, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1390, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1391, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1392, reward -75.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1393, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1394, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1395, reward 34.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1396, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1397, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1398, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1399, reward -193.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1400, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1401, reward -160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1402, reward -280.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1403, reward -266.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1404, reward -239.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1405, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1406, reward -52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1407, reward 148.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1408, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1409, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1410, reward 170.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1411, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1412, reward 254.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1413, reward 166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1414, reward -279.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1415, reward -1.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1416, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1417, reward -267.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1418, reward -174.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1419, reward -267.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1420, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1421, reward -280.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1422, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1423, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1424, reward -383.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1425, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1426, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1427, reward -51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1428, reward -227.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1429, reward 160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1430, reward -251.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1431, reward 44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1432, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1433, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1434, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1435, reward -213.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1436, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1437, reward 152.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1438, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1439, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1440, reward -266.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1441, reward -145.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1442, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1443, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1444, reward 112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1445, reward 130.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1446, reward -317.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1447, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1448, reward 24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1449, reward 101.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1450, reward -42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1451, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1452, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1453, reward -140.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1454, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1455, reward -16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1456, reward 288.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1457, reward 96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1458, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1459, reward 51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1460, reward 112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1461, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1462, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1463, reward -72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1464, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1465, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1466, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1467, reward 11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1468, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1469, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1470, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1471, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1472, reward 151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1473, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1474, reward -204.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1475, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1476, reward -344.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1477, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1478, reward -18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1479, reward 113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1480, reward -20.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1481, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1482, reward 153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1483, reward -20.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1484, reward -192.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1485, reward -199.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1486, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1487, reward -129.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1488, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1489, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1490, reward 57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1491, reward 96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1492, reward 192.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1493, reward -84.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1494, reward -155.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1495, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1496, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1497, reward -132.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1498, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1499, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1500, reward -17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1501, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1502, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1503, reward -388.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1504, reward 161.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1505, reward 278.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1506, reward 153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1507, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1508, reward -52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1509, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1510, reward 189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1511, reward 182.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1512, reward 3.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1513, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1514, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1515, reward 62.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1516, reward -60.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1517, reward -318.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1518, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1519, reward -201.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1520, reward 42.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1521, reward 94.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1522, reward -320.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1523, reward -349.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1524, reward -92.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1525, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1526, reward -196.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1527, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1528, reward -83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1529, reward -225.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1530, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1531, reward 6.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1532, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1533, reward 7.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1534, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1535, reward 107.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1536, reward -267.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1537, reward -83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1538, reward -186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1539, reward 66.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1540, reward 290.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1541, reward 125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1542, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1543, reward 56.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1544, reward 40.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1545, reward -82.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1546, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1547, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1548, reward -3.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1549, reward -160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1550, reward -221.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1551, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1552, reward 90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1553, reward -48.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1554, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1555, reward -72.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1556, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1557, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1558, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1559, reward 99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1560, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1561, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1562, reward 16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1563, reward -192.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1564, reward 119.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1565, reward 90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1566, reward 12.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1567, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1568, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1569, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1570, reward 38.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1571, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1572, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1573, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1574, reward -279.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1575, reward -99.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1576, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1577, reward -194.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1578, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1579, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1580, reward -388.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1581, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1582, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1583, reward -84.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1584, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1585, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1586, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1587, reward -267.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1588, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1589, reward 201.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1590, reward -22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1591, reward 183.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1592, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1593, reward 198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1594, reward 124.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1595, reward 53.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1596, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1597, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1598, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1599, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1600, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1601, reward -141.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1602, reward 68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1603, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1604, reward -118.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1605, reward -280.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1606, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1607, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1608, reward -90.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1609, reward -51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1610, reward -14.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1611, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1612, reward -136.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1613, reward -329.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1614, reward -96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1615, reward 9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1616, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1617, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1618, reward -114.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1619, reward -136.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1620, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1621, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1622, reward -320.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1623, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1624, reward -356.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1625, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1626, reward -82.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1627, reward -313.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1628, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1629, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1630, reward 161.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1631, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1632, reward -209.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1633, reward 220.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1634, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1635, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1636, reward -316.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1637, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1638, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1639, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1640, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1641, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1642, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1643, reward -342.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1644, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1645, reward -210.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1646, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1647, reward 36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1648, reward 151.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1649, reward 97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1650, reward 87.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1651, reward 51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1652, reward -211.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1653, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1654, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1655, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1656, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1657, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1658, reward -442.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1659, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1660, reward 153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1661, reward -52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1662, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1663, reward -68.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1664, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1665, reward -102.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1666, reward -74.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1667, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1668, reward -51.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1669, reward 124.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1670, reward -128.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1671, reward -239.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1672, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1673, reward -273.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1674, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1675, reward -169.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1676, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1677, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1678, reward -190.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1679, reward -33.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1680, reward 224.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1681, reward -18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1682, reward -200.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1683, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1684, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1685, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1686, reward -64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1687, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1688, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1689, reward -257.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1690, reward -253.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1691, reward 292.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1692, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1693, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1694, reward -96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1695, reward -315.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1696, reward -234.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1697, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1698, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1699, reward -298.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1700, reward 178.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1701, reward -77.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1702, reward -6.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1703, reward -189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1704, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1705, reward -221.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1706, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1707, reward -133.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1708, reward 182.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1709, reward 181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1710, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1711, reward -119.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1712, reward -60.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1713, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1714, reward 44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1715, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1716, reward 49.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1717, reward -311.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1718, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1719, reward 70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1720, reward 11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1721, reward -172.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1722, reward -377.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1723, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1724, reward -232.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1725, reward 338.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1726, reward -351.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1727, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1728, reward -160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1729, reward 161.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1730, reward -96.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1731, reward -130.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1732, reward -45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1733, reward -93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1734, reward 102.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1735, reward 63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1736, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1737, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1738, reward 3.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1739, reward -126.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1740, reward 64.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1741, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1742, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1743, reward -199.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1744, reward 30.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1745, reward 52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1746, reward 35.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1747, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1748, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1749, reward -24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1750, reward -167.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1751, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1752, reward -143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1753, reward 22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1754, reward 148.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1755, reward 106.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1756, reward -15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1757, reward 189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1758, reward 71.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1759, reward -234.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1760, reward -181.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1761, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1762, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1763, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1764, reward 83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1765, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1766, reward -109.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1767, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1768, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1769, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1770, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1771, reward -44.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1772, reward -308.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1773, reward 220.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1774, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1775, reward -22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1776, reward -32.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1777, reward -82.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1778, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1779, reward -10.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1780, reward 184.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1781, reward -23.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1782, reward 174.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1783, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1784, reward -123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1785, reward -298.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1786, reward 76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1787, reward -120.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1788, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1789, reward -174.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1790, reward -112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1791, reward 45.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1792, reward -154.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1793, reward -113.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1794, reward 108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1795, reward 200.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1796, reward 15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1797, reward -14.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1798, reward -482.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1799, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1800, reward 143.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1801, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1802, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1803, reward -131.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1804, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1805, reward 52.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1806, reward 152.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1807, reward -103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1808, reward 24.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1809, reward -175.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1810, reward -136.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1811, reward -233.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1812, reward -171.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1813, reward 70.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1814, reward -9.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1815, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1816, reward -36.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1817, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1818, reward -257.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1819, reward 157.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1820, reward 57.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1821, reward -59.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1822, reward -153.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1823, reward 123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1824, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1825, reward -316.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1826, reward 102.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1827, reward -46.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1828, reward -22.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1829, reward 89.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1830, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1831, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1832, reward 38.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1833, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1834, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1835, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1836, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1837, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1838, reward -28.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1839, reward -81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1840, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1841, reward 13.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1842, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1843, reward 75.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1844, reward -16.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1845, reward -261.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1846, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1847, reward 103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1848, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1849, reward 139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1850, reward 123.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1851, reward 186.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1852, reward 144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1853, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1854, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1855, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1856, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1857, reward 0.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1858, reward 227.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1859, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1860, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1861, reward -11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1862, reward -252.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1863, reward 18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1864, reward -47.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1865, reward 198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1866, reward -266.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1867, reward -18.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1868, reward 144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1869, reward -5.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1870, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1871, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1872, reward 69.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1873, reward 116.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1874, reward -118.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1875, reward 247.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1876, reward -38.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1877, reward -135.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1878, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1879, reward -329.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1880, reward -144.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1881, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1882, reward 188.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1883, reward -112.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1884, reward -78.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1885, reward -236.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1886, reward -347.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1887, reward -69.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1888, reward 17.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1889, reward -73.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1890, reward -122.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1891, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1892, reward -83.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1893, reward 81.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1894, reward 8.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1895, reward 154.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1896, reward 115.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1897, reward 130.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1898, reward -257.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1899, reward -187.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1900, reward -242.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1901, reward -159.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1902, reward -176.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1903, reward -367.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1904, reward -208.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1905, reward 80.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1906, reward -163.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1907, reward 30.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1908, reward -216.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1909, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1910, reward -11.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1911, reward -76.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1912, reward -37.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1913, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1914, reward -342.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1915, reward -180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1916, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1917, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1918, reward -104.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1919, reward -166.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1920, reward 117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1921, reward -108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1922, reward -139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1923, reward 279.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1924, reward -41.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1925, reward -200.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1926, reward -302.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1927, reward 31.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1928, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1929, reward -124.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1930, reward -270.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1931, reward -203.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1932, reward 93.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1933, reward -86.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1934, reward -75.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1935, reward 139.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1936, reward -198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1937, reward -207.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1938, reward -248.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1939, reward -53.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 1940, reward -100.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1941, reward 198.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1942, reward -120.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1943, reward -311.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1944, reward 111.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1945, reward 222.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1946, reward -117.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1947, reward -163.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1948, reward 125.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1949, reward -63.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1950, reward 4.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1951, reward 142.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1952, reward 189.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1953, reward -91.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1954, reward -242.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1955, reward 180.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1956, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1957, reward -54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1958, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1959, reward -162.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1960, reward 54.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1961, reward -324.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1962, reward 27.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1963, reward 26.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1964, reward -392.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1965, reward -295.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1966, reward -185.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1967, reward 85.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1968, reward -159.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1969, reward -215.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1970, reward -288.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1971, reward -103.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1972, reward 15.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1973, reward 108.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1974, reward -194.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1975, reward 75.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1976, reward -164.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1977, reward -149.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1978, reward 168.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1979, reward -55.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1980, reward 67.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1981, reward -160.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1982, reward -158.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1983, reward -190.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1984, reward -50.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1985, reward -79.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1986, reward 58.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1987, reward -226.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1988, reward 92.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1989, reward -197.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1990, reward -191.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1991, reward 33.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1992, reward -95.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1993, reward -248.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1994, reward -212.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1995, reward -284.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1996, reward -66.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1997, reward -97.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1998, reward -19.0, memory_length 2000, epsilon 0.009920974201040588\n",
      "episode 1999, reward -168.0, memory_length 2000, epsilon 0.009920974201040588\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# agent needs to be initialised outside the loop since the DQN\n",
    "# network will be initialised along with the agent\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size)\n",
    "\n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here   \n",
    "    # Call the environment   \n",
    "    # Call all the initialised variables of the environment\n",
    "    score = 0 \n",
    "    action_space, state_space, state = env.reset()\n",
    "    terminal_state = False\n",
    "    #Call the DQN agent\n",
    "        \n",
    "    while not terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        # populate update_input and update_output and the lists rewards, actions, done\n",
    "       \n",
    "        # get action for the current state and take a step in the environment\n",
    "        action = agent.get_action(state)       \n",
    "        reward = env.reward_func(state, action, Time_matrix) \n",
    "        next_state, terminal_state = env.next_state_func(state, action, Time_matrix)\n",
    "        \n",
    "        # save the sample <s, a, r, s', done> to the replay memory\n",
    "        agent.append_sample(state, action, reward, next_state, terminal_state)\n",
    "\n",
    "        # train after each step\n",
    "        agent.train_model()\n",
    "\n",
    "        # add reward to the total score of this episode\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "\n",
    "    # epsilon decay\n",
    "    if agent.epsilon_max > agent.epsilon_min:\n",
    "        agent.epsilon_max *= agent.epsilon_decay\n",
    "\n",
    "    # every episode:\n",
    "    print(\"episode {0}, reward {1}, memory_length {2}, epsilon {3}\".format(episode,\n",
    "                                                                         score,\n",
    "                                                                         len(agent.memory),\n",
    "                                                                         agent.epsilon_max))\n",
    "    # every few episodes:\n",
    "    #if episode % 10 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "        # save model weights\n",
    "        # agent.save_model_weights(name=\"model_weights.h5\")\n",
    "    # every few episodes:\n",
    "    if episode % 100 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "        # save model weights\n",
    "        save_tracking_states() \n",
    "        save_obj(States_track,'States_tracked') \n",
    "        agent.save(name=\"CarPol_model.h5\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.arange(0,10000)\n",
    "epsilon = []\n",
    "for i in range(0,10000):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
