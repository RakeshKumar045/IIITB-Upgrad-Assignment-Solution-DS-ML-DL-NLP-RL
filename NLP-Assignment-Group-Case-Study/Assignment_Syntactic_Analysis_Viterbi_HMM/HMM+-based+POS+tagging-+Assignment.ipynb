{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Red'>Problem Statement :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Blue'># POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In this project we apply techniques to improve Vanilla Viterbi Algorithm. Following are the steps followed:\n",
    "\n",
    "1. plain vanilla Viterbi Algorithm is developed.\n",
    "\n",
    "\n",
    "2. Lexicon Technique - approach:\n",
    "    * Unigram, Bigram and Trigram are considered in case of unknown words.\n",
    "\n",
    "3. Rule Base Technique - approach:\n",
    "    * Rule Base is considered in case of unknown words.\n",
    "    \n",
    "4. Combine Technique - approach:\n",
    "    * Combine (use for Unigram, Bigram, Trigram, Rule Base) is considered in case of unknown words.\n",
    "    \n",
    "5. Viterbi Modification-Technique I - approach:\n",
    "    * Transition probability is considered in case of unknown words.\n",
    "\n",
    "6. Viterbi Modification-Technique II - approach:\n",
    "     * backoff to a rule based tagger in case of an unknown word.\n",
    "     * The above technique is modified by using transition probability in approach 2 above if rule based tagger returns default noun tag ('NN').\n",
    "\n",
    "7. The modified Viterbi algorithms are first tested on sampled test data for comparison.\n",
    "\n",
    "\n",
    "8. The final algorithm and vanilla Viterbi Algorithm are the tested on full testing data for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 1 : Import the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from colorama import Fore\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Green'>Step 2 : Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# let's check some of the tagged data\n",
    "print(nltk_data[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 3: Split data into train, validation set in the ratio train=95 : test=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set = train_test_split(nltk_data, test_size = 0.05, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3718, 196)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set) , len(test_set) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> Understanding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Reliance', 'NOUN'),\n",
       " ('confirmed', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('filing', 'NOUN'),\n",
       " ('but', 'CONJ'),\n",
       " ('would', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('elaborate', 'VERB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of train and test tagged words\n",
    "\n",
    "\n",
    "train_tagged_words = [word for sentence in train_set for word in sentence ]\n",
    "test_tagged_words = [word[0] for sentence in test_set for word in sentence ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95547, 5129)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tagged_words) , len(test_tagged_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confirmed', 'VERB'), ('the', 'DET'), ('filing', 'NOUN'), ('but', 'CONJ')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the tagged words.\n",
    "train_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'company', 'said', '0', 'it', 'is', 'in', 'the', 'process']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the tagged words.\n",
    "test_tagged_words[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique tags are present in training data\n",
    "\n",
    "tags = {tag for word, tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Tags :  {'VERB', 'NOUN', 'X', 'ADP', 'ADV', 'CONJ', 'PRT', '.', 'PRON', 'ADJ', 'DET', 'NUM'}\n"
     ]
    }
   ],
   "source": [
    "print(len(tags))\n",
    "print(\"Tags : \", tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique vocalbulary are present in training data\n",
    "\n",
    "vocal = {word for word, tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "\n",
      "12100\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Fore.GREEN}\\n\")\n",
    "print(len(vocal))\n",
    "# print(\"vocal : \", vocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 4: POS Tagging algorithm using Hidden Markov Model (HMM)\n",
    "We'll use the HMM algorithm to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. In other words, to every word w, assign the tag t that maximises the likelihood P(t/w).\n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t).\n",
    "\n",
    "Now:\n",
    "\n",
    "P(w/t): is the emission probability of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t).\n",
    "\n",
    "P(t): is the probability of tag (also transition probability), and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of say a tag being NN will depend only on the previous tag t(n-1). So for e.g. if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'>Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'>  Function to compute emission probabilties for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> Function to compute transition probabilties for a given tag and previous tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    \n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    \n",
    "    count_of_t1 = len(t1_tags)\n",
    "    \n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    \n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    \n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 8281)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN','DET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> Creating function t x t transition matrix  of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "def tag_matrix(tags_val = tags):\n",
    "    tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "    \n",
    "    for i, t1 in enumerate(list(tags)):\n",
    "        \n",
    "        for j, t2 in enumerate(list(tags)): \n",
    "            \n",
    "            tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    "            \n",
    "    return tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix = tag_matrix(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>X</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.1692</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>0.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2406</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.2039</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>0.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.3247</td>\n",
       "      <td>0.0622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.3435</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.1371</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.0305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.4053</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.0567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.4855</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.3502</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.1849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       VERB   NOUN      X    ADP    ADV   CONJ    PRT      .   PRON    ADJ  \\\n",
       "VERB 0.1692 0.1101 0.2175 0.0920 0.0820 0.0056 0.0307 0.0349 0.0358 0.0650   \n",
       "NOUN 0.1477 0.2636 0.0292 0.1765 0.0171 0.0427 0.0434 0.2406 0.0046 0.0122   \n",
       "X    0.2039 0.0624 0.0764 0.1426 0.0250 0.0107 0.1852 0.1636 0.0555 0.0172   \n",
       "ADP  0.0083 0.3210 0.0344 0.0169 0.0140 0.0010 0.0014 0.0390 0.0700 0.1070   \n",
       "ADV  0.3435 0.0315 0.0232 0.1186 0.0805 0.0070 0.0142 0.1371 0.0149 0.1292   \n",
       "CONJ 0.1567 0.3491 0.0088 0.0525 0.0553 0.0005 0.0046 0.0349 0.0581 0.1181   \n",
       "PRT  0.4053 0.2478 0.0135 0.0201 0.0102 0.0023 0.0016 0.0438 0.0178 0.0830   \n",
       ".    0.0891 0.2222 0.0270 0.0913 0.0523 0.0575 0.0024 0.0933 0.0663 0.0440   \n",
       "PRON 0.4855 0.2109 0.0900 0.0230 0.0341 0.0054 0.0130 0.0410 0.0077 0.0731   \n",
       "ADJ  0.0117 0.6996 0.0211 0.0783 0.0048 0.0170 0.0107 0.0639 0.0003 0.0664   \n",
       "DET  0.0399 0.6381 0.0454 0.0095 0.0124 0.0005 0.0002 0.0180 0.0037 0.2043   \n",
       "NUM  0.0188 0.3502 0.2105 0.0360 0.0030 0.0137 0.0265 0.1173 0.0015 0.0342   \n",
       "\n",
       "        DET    NUM  \n",
       "VERB 0.1344 0.0229  \n",
       "NOUN 0.0129 0.0095  \n",
       "X    0.0547 0.0029  \n",
       "ADP  0.3247 0.0622  \n",
       "ADV  0.0699 0.0305  \n",
       "CONJ 0.1213 0.0400  \n",
       "PRT  0.0979 0.0567  \n",
       ".    0.1733 0.0810  \n",
       "PRON 0.0100 0.0065  \n",
       "ADJ  0.0049 0.0213  \n",
       "DET  0.0057 0.0222  \n",
       "NUM  0.0033 0.1849  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VERB   0.0891\n",
       "NOUN   0.2222\n",
       "X      0.0270\n",
       "ADP    0.0913\n",
       "ADV    0.0523\n",
       "CONJ   0.0575\n",
       "PRT    0.0024\n",
       ".      0.0933\n",
       "PRON   0.0663\n",
       "ADJ    0.0440\n",
       "DET    0.1733\n",
       "NUM    0.0810\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6wAAAKrCAYAAAD1SQBIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdf7SudV0n/PeHA4gIiCj+SFTAoSnU1EJsZVOp2aLyZ84YaJplnanGx9SZJuyHT1rLmbGspzGn8ViWNhZWZlHh6Goky5585EhEklqEAic0BREBETjsz/PH3ke3m73v+8A5976+eL9ernt53dd17+t+b9bi6Od8vtfnW90dAAAAGM0hUwcAAACAzShYAQAAGJKCFQAAgCEpWAEAABiSghUAAIAhHbroL3juQ77LGOI1H9t73dQRhvFNh91v6gjDeMfNV0wdYRi3rOydOsIwPnLtlVNHGMLRdzty6gjDOKRq6gjDKP8svuCYw+4xdYRh/Osj7z91hGG895oPTx1hKJ+98bIviz80br36ssnrqsPuc/K2/7PUYQUAAGBIClYAAACGpGAFAABgSAt/hhUAAIADtHLb1AkmocMKAADAkHRYAQAARtcrUyeYhA4rAAAAQ1KwAgAAMCRLggEAAEa3YkkwAAAADEOHFQAAYHBt6BIAAACMQ8EKAADAkCwJBgAAGJ2hSwAAADAOHVYAAIDRGboEAAAA41CwAgAAMCRLggEAAEa3ctvUCSahwwoAAMCQdFgBAABGZ+gSAAAAjEPBCgAAwJAsCQYAABjdiiXBAAAAMIw71GGtqvskuaa7e0F5AAAA2KANXfpSVfX1VfXnVfUHVfXoqvpgkg8m+ZeqOmP7IgIAALCMZi0J/pUkr0ryO0neneQHuvv+Sb4pyX+ZddOq2llVu6tq9z/e8NGDFhYAAIDlMatgPbS739Xdv5fkE939viTp7g/Pu2l37+ru07r7tFOOOulgZQUAAFhOKyvTvyYwq2Bdn+imDdc8wwoAAMBCzRq69Miq+mySSnL3teOsvT9i4ckAAABYalsWrN29YzuDAAAAsAVTgvdPVR1bVT+5iDAAAACwz5Yd1qp6UJKfTvIVSf4wyW8n+dkkz1s7BgAAYDus3DZ1gknMeob1zUnek+RtSc5I8r4klyR5RHd/YhuyAQAAsMRmFazHdffPrB2/s6r+JcljuvvmxccCAABg2c0qWFNV98rqVOAk+USSI6vqHknS3Z9ecDYAAACSpR26NKtgvWeSD+SLBWuSXLj2353k5EWFAgAAgFnb2py4jTkAAADYyspydli33Namqr5n3fHjNlx74SJDAQAAwKx9WF+67vi1G659/wKyAAAAwBfMeoa1tjje7D0AAACLsqRDl2Z1WHuL483eAwAAwEE1q8P6VVV1cVa7qQ9dO87aexOCAQAAtsuSDl2aVbCen+RVSf45OqoAAABss1kF67uS/EKSByR5a5Lf6e6LtiUVAAAAS2/WPqy/nOSXq+ohSc5M8htVdUSS30lyTnf/wzZlBAAAWGrdt00dYRKzhi4lSbr78u7+b9396CTPTvKMJB9aeDIAAACW2qwlwUmSqjosyRlZ7bI+Mcl7krxiwbkAAADYZ0m3tdmyYK2qJyU5K8l3Jnl/knOS7OzuG7cpGwAAAEtsVof1J5L8dpL/1N2f3qY8AAAAkGT20KXHb2cQAAAAtrCk+7DOHboEAAAAU5g7dOlA3dC3Lvor7jKec8gDpo4wjJdd/b6pIwzjGfd51NQRhvHWT+6eOsIw7n3kMVNHYDAvvufXTR1hGD/98fOnjjCM62++aeoIw/jnG66eOsIwOj11BBZhSYcu6bACAAAwJAUrAAAAQ1r4kmAAAAAO0MptUyeYhA4rAAAAQ1KwAgAAMCRLggEAAEZnSjAAAACMQ4cVAABgdCs6rAAAADAMBSsAAABDsiQYAABgdIYuAQAAwDh0WAEAAEZn6BIAAACMQ8EKAADAkCwJBgAAGJ0lwQAAADAOHVYAAIDBdd82dYRJ6LACAAAwJAUrAAAAQ7IkGAAAYHSGLgEAAMA4dFgBAABG1zqsAAAAMAwFKwAAAEOyJBgAAGB0Szp0aWbBWlUPnnW9u684uHEAAABg1bwO658m6SS17lwnOT7JfZPs2OyHqmpnkp1J8qh7PSInHvWQA08KAADAUplZsHb3I9a/r6oTk/x4km9N8qoZP7crya4kecaDn9IHGhIAAGCpmRK8tao6pap+M8k7knwgyand/dpFBgMAAGC5zXuG9eFJfjLJw5K8OskLuvu27QgGAADAGkOXNvW3Sa7M6rOspyc5veqLj7N294sWFw0AAIBlNq9gfUFWhywBAADAtpo3dOk3tykHAAAAW1nSoUvznmH943xph7WTXJ3k/O7+X4sMBgAAwHKbtyT4FzY5d1yS76mqh3f32QvIBAAAwHp3gaFLVXVGkl9OsiPJr3X3f93kM89K8jNZbYb+bXc/e9Y95y0Jfs8WQc7N6vY2ClYAAIAlV1U7krwuyZOS7ElyQVWd291/v+4zpyR5WZLHdfe1VXXfeffdr31YN7K1DQAAAOucnuTS7r6su29Jck6Sp234zA8meV13X5sk3f3JeTed9wzrcZucvleS5yW5ZH9SAwAAcIAGWBJcVTuT7Fx3ald371o7fmBWt0TdZ0+Sx264xVeu3eevsrps+Ge6+3/P+s55z7B+IKtri/dtvtpJrklyfpIfnvOzAAAAfJlYK053bXG5Njm3cYvUQ5OckuRbkpyQ5C/XZiN9ZqvvnPcM60mzrgMAALANxt/WZk+SB617f0KSqzb5zPu6+9YkH62qj2S1gL1gq5vOfYa1qu5bVa+oqt+vqt9bO577cCwAAABL44Ikp1TVSVV1eJIzk5y74TN/mOTxSVJV98nqEuHLZt10ZsFaVY/LF6vdNyfZt/fq+9euAQAAsOS6e2+SFyZ5Z5IPJfnd7r6kql5ZVU9d+9g7k1xTVX+f1cdMf6y7r5l133nPsL4mydO7+2/Wnfujqnp7ktfn9g/RAgAAcLANMHRpnu4+L8l5G869fN1xJ3np2mu/zFsSfMyGYnXfF12U5Oj9/RIAAAC4o+Z1WKuq7rVvn5x1J4/LndzDFQAAgDto/KFLCzGv6PylJO+qqm+uqqPXXt+S5B1r1wAAAGAh5m1rs6uqrkrys0ketnb6kiQ/191/vOhwAAAALK95S4LT3X+S5E+2IQsAAACbuQsMXVqEmQVrVb18xuXu7p89yHkAAAAgyfwO642bnLtHkhckuXdWlwoDAACwSEs6dGneM6yv2XdcVUcn+dEk35fknKzu0QoAAAALMfcZ1rUtbF6a5DlJ3pTkazducwMAAAAH27xnWH8+yXcl2ZXkEd19w7akAgAA4IsMXdrUf0xyc5KfSvKTVbXvfGV16NIx877gpEPucUABv5y8+oZLpo4wjPsfedzUEYZxzcrnp44wjEMP2TF1hGFc+3l/P5gkz7//108dYRgX92ZjJZbTVxx976kjDOPqmz47dYRh3PuIo6eOMIyrbvj01BHgoJn3DOsh2xUEAAAA1pv7DCsAAAATW9IlwTqoAAAADEmHFQAAYHTdUyeYhA4rAAAAQ1KwAgAAMCRLggEAAEZn6BIAAACMQ4cVAABgdDqsAAAAMA4FKwAAAEOyJBgAAGB0bUkwAAAADEOHFQAAYHSGLgEAAMA4FKwAAAAMyZJgAACA0XVPnWASOqwAAAAMSYcVAABgdIYuAQAAwDgUrAAAAAzJkmAAAIDRWRIMAAAA49BhBQAAGF3rsH6JqnrQjGv/ZjFxAAAAYNWsJcHvqar/XFVf6MJW1f2q6n8l+cXFRwMAAGCZzSpYvy7JQ5P8TVU9oap+NMn7k/x1ksfOumlV7ayq3VW1++Lr/+ngpQUAAFhCvdKTv6aw5TOs3X1tkn+/Vqj+WZKrknx9d++Zd9Pu3pVkV5K89MQzp/nNAAAAuEub9QzrsVX1+iTfl+SMJL+f5B1V9YTtCgcAAMDymjUl+MIk/yPJf+juvUneVVWPSvI/qury7j5rWxICAAAsuyXdh3VWwfpNG5f/dvdFSb6hqn5wsbEAAABYdrOeYd3yWdXufsNi4gAAAHA79mEFAACAcShYAQAAGNKsZ1gBAAAYwUT7oE5NhxUAAIAh6bACAACMbkm3tdFhBQAAYEgKVgAAAIZkSTAAAMDoLAkGAACAceiwAgAAjK5tawMAAADDULACAAAwJEuCAQAARmfoEgAAAIxDhxUAAGB0K4YuAQAAwDAUrAAAAAzJkmAAAIDRtaFLAAAAMAwFKwAAAEOyJBgAAGB0SzoleOEF6698/L2L/oq7jD899nFTRxjGWTf9zdQRhnHFDZ+cOsIwVno5/yDezG1Lujn4Rr9+1f87dYRh3PvuR08dYRj3PPyoqSMM41H3OnnqCMN45d7jp44wjB885h+mjgAHjQ4rAADA4HpJ/zLbM6wAAAAMScEKAADAkCwJBgAAGN2SDl3SYQUAAGBIOqwAAACja0OXAAAAYBgKVgAAAIZkSTAAAMDoDF0CAACAceiwAgAAjG7F0CUAAAAYhoIVAACAIVkSDAAAMDpDlwAAAGAcOqwAAACja0OXAAAAYBgKVgAAAIZkSTAAAMDoDF0CAACAO6eqzqiqj1TVpVV19ibXn19Vn6qqi9ZePzDvnjqsAAAAg+uVsYcuVdWOJK9L8qQke5JcUFXndvffb/joW7v7hft7Xx1WAAAADtTpSS7t7su6+5Yk5yR52oHeVMEKAADAgXpgkivXvd+zdm6jZ1bVxVX1+1X1oHk3VbACAACMbqUnf1XVzqrave61c13C2iT1xklRf5zkxO7+miR/luRN835tz7ACAAAwV3fvSrJri8t7kqzvmJ6Q5KoNP3/NurdvSPLf5n3nzA5rVR1fVadV1bHzbgQAAMDSuiDJKVV1UlUdnuTMJOeu/0BVPWDd26cm+dC8m27ZYV0bMfyqJP+U5KSq2tnd5271eQAAABZk8H1Yu3tvVb0wyTuT7Ejyxu6+pKpemWT3Wi35oqp6apK9ST6d5Pnz7jtrSfCLkzysuz9VVScneUs2VMhbWVvLvDNJduw4NofsuMf+/BgAAAB3Ud19XpLzNpx7+brjlyV52R2556yC9Zbu/tTajS+rqrvdgaBfWNt8+N1OGPuvAgAAAEbXY+/DuiizCtYTquq/b/W+u1+0uFgAAAAsu1kF649teP+BRQYBAACA9bYsWLt77p44AAAAbIPBhy4tyrxtbb63qi6sqhvXXrur6nnbFQ4AAIDlNWtbm+dldVLwS5NcmKSSfG2Sn6+qdPebtyciAADAcmsd1tv5kSTP6O7zu/u67v5Md787yTPXrgEAAMDCzCpYj+nuj208uXbumEUFAgAAgGT2lOCb7uQ1AAAADqYlXRI8q2D96qq6eJPzleTkBeUBAACAJHMK1k3OVZITkvzEYuIAAABwOysrUyeYxKx9WC/fd1xVj0ry7CTPSvLRJG9bfDQAAACW2axtbb4yyZlJzkpyTZK3Jqnufvw2ZQMAAGCJzVoS/OEkf5nkKd19aZJU1Uu2JRUAAABftKRDl2Zta/PMJJ9Icn5VvaGqnpjVZ1gBAABg4WY9w/r2JG+vqnskeXqSlyS5X1X9apK3d/e7tikjAADActNh3Vx339jdb+nuJ2d1QvBFSc5eeDIAAACW2tyCdb3u/nR3v767n7CoQAAAAJDMHroEAADAALotCQYAAIBh6LACAACMztAlAAAAGIeCFQAAgCFZEgwAADA6S4IBAABgHAvvsP7FvU9f9FfcZXzH9RdOHWEYe1dumzrCME4/7pSpIwzjU7deP3WEYfzDZ/ZMHWEYOw7ZMXWEITzmng+dOsIw/s+nPjh1hGGcdJ/jp44wjB9e+aepIwzjMzffMHUEOGgsCQZgWIpVAFjVlgQDAADAOHRYAQAARqfDCgAAAONQsAIAADAkS4IBAABGtzJ1gGnosAIAADAkHVYAAIDB2dYGAAAABqJgBQAAYEiWBAMAAIzOkmAAAAAYhw4rAADA6GxrAwAAAONQsAIAADAkS4IBAAAGZx9WAAAAGIgOKwAAwOgMXQIAAIBxKFgBAAAYkiXBAAAAgzN0CQAAAAaiYAUAAGBIlgQDAACMzpRgAAAAGMeWHdaqOq27d29nGAAAAG6vdVhv5w1V9Y9V9cqqOnXbEgEAAEBmFKzd/egkT05yW5Lfr6qLqurHq+oh825aVTurandV7f7Dz330IMYFAABgWcx8hrW7P9Ldr+juU5N8b5Jjk7y7qv5qzs/t6u7Tuvu0px950kGMCwAAsIRWBnhNYL+GLlXVIUnum+R+Se6R5FOLDAUAAAAzt7Wpqn+T5KwkT0/ywSTnJHlJd1+3DdkAAADI8g5dmjUl+MokV2S1SH1Fd//LtqUCAABg6c3qsH5jd1++bUkAAABgnVlTgi+vqu+tqgur6sa11+6qet52BgQAAFh6Uw9cmmhJ8qwlwc9L8uIkL01yYZJK8rVJfr6q0t1v3p6IAAAALKNZS4J/JMkzuvtj6869u6qemdXnWhWsAAAA22BZhy7N2tbmmA3FapJk7dwxiwoEAAAAyeyC9aY7eQ0AAAAO2KwlwV9dVRdvcr6SnLygPAAAAGywrEuCZxasm5yrJCck+YnFxAEAAIBVWxas6/dgrapHJXl2kmcl+WiSty0+GgAAAIkO6+1U1VcmOTPJWUmuSfLWJNXdj9+mbAAAACyxWUuCP5zkL5M8pbsvTZKqesm2pAIAAGDpzSpYn5nVDuv5VfW/s7r3am1LKgAAAL6ol7MU23Jbm+5+e3d/d5KvSvLnSV6S5H5V9atV9W3blA8AAIAlNWsf1iRJd9/Y3W/p7idndULwRUnOXngyAAAAkqwOXZr6NYW5Bet63f3p7n59dz9hUYEAAAAguYMFKwAAAGyXWUOXAAAAGECvGLoEAAAAw1CwAgAAMCRLggEAAAY31ZTeqemwAgAAMCQdVgAAgMF1L+fQpYUXrL902JL2rjfxzmMePnWEYXzjNbunjjCMf/rcJ6aOMIyq5fyDeDMr3VNHGELftnfqCMN432f+ceoIw7j/kcdOHWEYt7R/R/Z50N2OmzrCMK675YapI8BBY0kwAAAAQ7IkGAAAYHCGLgEAAMBAdFgBAAAG1yvLOetDhxUAAIADVlVnVNVHqurSqjp7xuf+bVV1VZ02754KVgAAAA5IVe1I8rok357k1CRnVdWpm3zu6CQvSvL/7c99FawAAACD657+NcfpSS7t7su6+5Yk5yR52iaf+9kkr07y+f35vRWsAAAAzFVVO6tq97rXznWXH5jkynXv96ydW//zj07yoO7+k/39TkOXAAAABjfC0KXu3pVk1xaXNwv4hb5sVR2S5JeSPP+OfKcOKwAAAAdqT5IHrXt/QpKr1r0/OsnDk/x5VX0sydcnOXfe4CUFKwAAAAfqgiSnVNVJVXV4kjOTnLvvYndf19336e4Tu/vEJO9L8tTu3j3rppYEAwAADG6EJcGzdPfeqnphkncm2ZHkjd19SVW9Msnu7j539h02p2AFAADggHX3eUnO23Du5Vt89lv2554KVgAAgMHtx7YyX5Y8wwoAAMCQFKwAAAAMyZJgAACAwY0+dGlRdFgBAAAYkg4rAADA4Lp1WAEAAGAYClYAAACGZEkwAADA4Hpl6gTT0GEFAABgSApWAAAAhmRJMAAAwOBWlnRK8MyCtaqOm3H55u6+8SDnAQAAgCTzO6wfSNJJNivnD62qJDm7u9+y/kJV7UyyM0m+7rhH5qFHnXjgSQEAAJbUsu7DOrNg7e6TZl2vquOTvCfJlxSs3b0rya4k+e6HPL0PMCMAAABLaN6S4AfPuNzdfWVV/fhBzgQAAABzlwT/aW6/JLiTHJ/kvkl2dPcfLygbAAAASXrFkuDb6e5HrH9fVScm+fEk35rkVQtLBQAAwNLbr21tquqUJD+Z5LFJXpPkRd196yKDAQAAsKqXdDLQvGdYH57VQvVhSV6d5AXdfdt2BAMAAGC5zeuw/m2SK7P6LOvpSU5f28omSdLdL1pcNAAAAJbZvIL1+7clBQAAAFsydGkT3f2mfcdVddTqqb5x4akAAABYeofM+0BV/XBVXZHk8iRXVNXlVfUji48GAABAkqx0Tf6awsyCtap+KslTknxLd9+7u++d5PFJvn3tGgAAACzEvA7rc5N8V3dftu/E2vGzkjxvkcEAAABYbnP3Ye3uz29y7qaqWllMJAAAANbriZbkTm1eh3VPVT1x48m1cx9fTCQAAACY32F9UZI/qqr3JvlAkk7ymCSPS/K0BWcDAAAgSffUCaYxr2C9Ocnzk3xlkoclqSR/keTXk9xuqTAAAAAcLPMK1v8nyU909xvXn6yq09auPWVRwQAAAFhu8wrWE7v74o0nu3t3VZ24kEQAAAB8ian2QZ3avKFLR8y4dveDGQQAAADWm1ewXlBVP7jxZFW9IKtDmAAAAFiw7pr8NYV5S4JfnOTtVfWcfLFAPS3J4UmeschgAAAALLeZBWt3/0uSb6iqxyd5+NrpP+3udy88GQAAAEttXoc1SdLd5yc5f8FZAAAA2MSy7sM67xlWAAAAmISCFQAAgCHt15JgAAAAprOs+7AuvGB9zf0/u+ivuMt468e/YuoIw6gs579wm/n052+YOsIwbl3ZO3UEBrOkj+ts6tBDdkwdYRifvOm6qSMM4+jDjpw6wjDudshhU0cYxhGHHj51BDhodFgBAAAGN9U+qFPzDCsAAABDUrACAAAwJEuCAQAABresQ5d0WAEAABiSDisAAMDglnVyvg4rAAAAQ1KwAgAAMCRLggEAAAZn6BIAAAAMRIcVAABgcK3DCgAAAONQsAIAADAkS4IBAAAGtzJ1gInosAIAADAkHVYAAIDBdQxdAgAAgGEoWAEAABiSJcEAAACDW+mpE0xDhxUAAIAhKVgBAAAYkiXBAAAAg1sxJRgAAADGocMKAAAwOPuwAgAAwEBmFqxV9a7tCgIAAADrzVsSfPy2pAAAAGBLK1MHmMi8gvWeVfVdW13s7j/Y7HxV7UyyM0n+64n/Os+571fc+YQAAAAspbkFa5InJ5s+4dtJNi1Yu3tXkl1JsuexT+gDCQgAALDslnXo0ryC9fLu/v5tSQIAAADrzJsSvJxlPAAAAJObV7A+d7OTVbWjqp6zgDwAAABssDLAawrzCtYrquplVfUrVfVtter/SnJZkmdtQz4AAACW1LxnWH8rybVJ/jrJDyT5sSSHJ3lad1+04GwAAADEtjZbObm7H5EkVfVrSa5O8uDuvn7hyQAAAFhq85YE37rvoLtvS/JRxSoAAADbYV6H9ZFV9dl8cVrw3de97+4+ZqHpAAAAsA/rZrp7x3YFAQAAgPVmFqxVdUSSH0ryr5JcnOSN3b13O4IBAACwamU5G6xzn2F9U5LTkvxdku9I8pqFJwIAAIDMf4b11HVTgn89yfsXHwkAAADmF6zrpwTvrVrSPjQAAMCEVgxd2tS+KcHJ6mRgU4IBAADYFjOfYe3uHd19zNrr6O4+dN2xYhUAAGAb9ACvearqjKr6SFVdWlVnb3L9h6rq76rqoqp6b1WdOu+e84YuAQAAwExVtSPJ65J8e5JTk5y1SUH62939iO5+VJJXJ/nFefdVsAIAAHCgTk9yaXdf1t23JDknydPWf6C7P7vu7T2yH43bec+wAgAAMLGVqQMkqaqdSXauO7Wru3etHT8wyZXrru1J8thN7vEfkrw0yeFJnjDvOxWsAAAAzLVWnO7a4vJmY4xv10Ht7tcleV1VPTvJTyX53lnfaUkwAAAAB2pPkgete39CkqtmfP6cJE+fd1MdVgAAgMGt1PD7sF6Q5JSqOinJPyc5M8mz13+gqk7p7n9ce/udSf4xcyhYAQAAOCDdvbeqXpjknUl2JHljd19SVa9Msru7z03ywqr61iS3Jrk2c5YDJwpWAACA4e3PPqhT6+7zkpy34dzL1x3/6B29p2dYAQAAGJKCFQAAgCEtfEnwUy6/edFfcZfxlCPuCo387XG3Qw+bOsIwHnr0A6aOMIyrb75u6gjDqPEHK2yLf77+mqkjDOOEu99n6gjDuO6wz00dYRif+rw/N/c549ivnjrCMC647ZapI7AAI+zDOgUdVgAAAIZk6BIAAMDgVpZ08ZUOKwAAAENSsAIAADAkS4IBAAAGt5LlXBOswwoAAMCQdFgBAAAGt6wbZOqwAgAAMCQFKwAAAEOyJBgAAGBw9mEFAACAgeiwAgAADG5l6gAT0WEFAABgSApWAAAAhmRJMAAAwODswwoAAAAD0WEFAAAYnG1tAAAAYCAKVgAAAIZkSTAAAMDg7MMKAAAAA1GwAgAAMCRLggEAAAZnSTAAAAAMRIcVAABgcG0f1jumqu5/MIMAAADAegeyJPjXt7pQVTurandV7b76c584gK8AAABgWd3pgrW7v3PGtV3dfVp3n3afIzViAQAADsTKAK8pGLoEAADAkAxdAgAAGJxtbQAAAGAgClYAAACGZEkwAADA4HrqABPRYQUAAGBIOqwAAACDW6mpE0xDhxUAAIAhKVgBAAAYkiXBAAAAg7MPKwAAAAxEhxUAAGBwOqwAAAAwEAUrAAAAQ7IkGAAAYHA9dYCJ6LACAAAwJAUrAAAAQ7IkGAAAYHArNXWCaeiwAgAAMCQdVgAAgMHZhxUAAAAGomAFAABgSJYEAwAADM4+rAAAADAQHVYAAIDBrSxpj3XhBetfPOtei/6Ku4yfO3dZZ3vd3slH3X/qCMO49LNXTR1hGIfv8Hdo+1z3+RunjjCEQw/ZMXWEYVz5uU9NHWEY137+hqkjDOPkez5g6gjD+O1PvH/qCMPoXs7Chi9PlgQDAAAwJO0MAACAwS3rWk0dVgAAAIakwwoAADC4ZX0yWYcVAACAISlYAQAAGJIlwQAAAIMzdAkAAAAGosMKAAAwuJWaOsE0dFgBAAAYkoIVAACAIVkSDAAAMLiVJd2JVYcVAACAIemwAgAADG45+6s6rAAAAAxKwQoAAMCQLAkGAAAY3MrUASaiwwoAAMCQFKwAAAAMyZJgAACAwdmHFQAAAAaiwwoAADC45eyv6rACAAAwKAUrAP+N7/QAABeHSURBVAAAQ7IkGAAAYHDLug/rzIK1qh4863p3X3Fw4wAAAMCqeR3WP83q87217lwnOT7JfZPsWFAuAAAA1tjWZhPd/Yju/pq1/35Ekqck+askNyR58VY/V1U7q2p3Ve3+jQ9qwgIAAHy5q6ozquojVXVpVZ29yfWXVtXfV9XFVfV/quoh8+65X0OXquqUqvrNJO9I8oEkp3b3a7f6fHfv6u7Tuvu073v4zFXFAAAA3MVV1Y4kr0vy7UlOTXJWVZ264WN/k+S07v6aJL+f5NXz7juzYK2qh1fV7yR5W5I/S/Lw7v617r71TvwOAAAA3Ak9wGuO05Nc2t2XdfctSc5J8rQv+R26z+/uz629fV+SE+bddN4zrH+b5MqsPst6epLTq774OGt3v2h+bgAAAO7qqmpnkp3rTu3q7l1rxw/Mau24z54kj51xuxdkdQXvTPMK1u+fdwMAAAAWa4RtbdaK011bXK5Nzm3amK2q70lyWpJvnvedMwvW7n7TupsetXqqb5x3UwAAAJbKniQPWvf+hCRXbfxQVX1rkp9M8s3dffO8m84dulRVP1xVVyS5PMkVVXV5Vf3IfscGAADgy90FSU6pqpOq6vAkZyY5d/0HqurRSV6f5Knd/cn9uenMDmtV/VSSb0jyLd192dq5k5P8clUd190/d8d/DwAAAO6IHnwf1u7eW1UvTPLOJDuSvLG7L6mqVybZ3d3nJvn5JEcl+b212UhXdPdTZ9133jOsz03yyO7+/Logl1XVs7I6kEnBCgAAQLr7vCTnbTj38nXH33pH7zmvYM36YnXduZuqaoTnfgEAAL7sLWvxNe8Z1j1V9cSNJ6vqCUk+vphIAAAAML/D+qIkf1RV703ygayOJX5MksdlwyawAAAAcDDN29bmkqp6eJJnJ3lYVvfW+Ysk/36zpcIAAAAcfCuDD11alP19hvWN689V1Y6qek53v2VhyQAAAFhqM59hrapjquplVfUrVfWkWvXCJJcledb2RAQAAFhuPcBrCvM6rL+V5Nokf53kB5P85ySHJ3lad1+04GwAAAAssXkF68nd/YgkqapfS3J1kgd39/ULTwYAAMBSm1ew3rrvoLtvq6qPKlYBAAC2l6FLm3tkVX02q9OBk+Tu6953dx+z0HQAAAAsrXnb2uzYriAAAACw3syCtaqOSPJDSf5VkouTvLG7925HMAAAAFatTB1gIjO3tUnypiSnJfm7JN+R5DULTwQAAACZ/wzrqeumBP96kvcvPhIAAADr9ZIOXZrXYV0/JdhSYAAAALbN/k4JTlYnA5sSDAAAwLYwJRgAAGBwyzp0aV6H9YAdv+viRX/FXcb1e/586gjDeN2Dnzh1hGE85Oj7Th1hGP9w7Z6pIwzj8EMPmzrCEPau3DZ1hGEcddiRU0cYxjU3XT91hGHc1sv6f2Fvb2XFP4t97nbo4VNHgINm4QUrAAAAB8bQJQAAABiIghUAAIAhWRIMAAAwuGV9SluHFQAAgCHpsAIAAAxupQ1dAgAAgGEoWAEAABiSJcEAAACDW84FwTqsAAAADEqHFQAAYHArS9pj1WEFAABgSApWAAAAhmRJMAAAwODakmAAAAAYh4IVAACAIVkSDAAAMLiVqQNMRIcVAACAIemwAgAADM4+rAAAADAQBSsAAABDsiQYAABgcPZhBQAAgIHosAIAAAzOtjYAAAAwEAUrAAAAQ9pySXBVvTbZ8snem5P8U5K3dPf1iwgGAADAqu7lHLo06xnW3XN+7mFJ/iDJkzZerKqdSXYmyaGH3is7dhx1IBkBAABYQlsWrN39pnk/XFXnbfGzu5LsSpIjjnjwcv5VAAAAwEGyYlub26uq762qC6vqxrXX7qp63r7r3f0di48IAADAMpr1DOvzkrw4yUuTXJikknxtkp+vqnT3m7cnIgAAAMto1jOsP5LkGd39sXXn3l1Vz0xyThIFKwAAwDawD+vtHbOhWE2SrJ07ZlGBAAAAIJndYb3pTl4DAADgIOolHbo0q2D96qq6eJPzleTkBeUBAACAJHMK1k3OVZITkvzEYuIAAADAqln7sF6+77iqHpXk2UmeleSjSd62+GgAAAAky7sP66xtbb4yyZlJzkpyTZK3Jqnufvw2ZQMAAGCJzVoS/OEkf5nkKd19aZJU1Uu2JRUAAABf0L2cHdZZ29o8M8knkpxfVW+oqidm9RlWAAAAWLgtC9bufnt3f3eSr0ry50lekuR+VfWrVfVt25QPAACAJTWrw5ok6e4bu/st3f3krE4IvijJ2QtPBgAAQJJkZYDXFOYWrOt196e7+/Xd/YRFBQIAAIDkDhasAAAAsF1mTQkGAABgAL2k+7DqsAIAADAkHVYAAIDBreiwAgAAwDgUrAAAAAzJkmAAAIDBdVsSDAAAAMPQYQUAABicoUsAAAAwEAUrAAAAQ1r4kuB73u3IRX/FXcZtH/2bqSMM4+jD7z51hGFcet1VU0cYxo5DdkwdYRg377116ggM5hOf+/TUEYZRUwcYyFPuccrUEYbx2us+MXWEYRxS/i35ctSWBAMAAMA4DF0CAAAY3IptbQAAAGAcClYAAACGZEkwAADA4JZzQbAOKwAAAIPSYQUAABjcypL2WHVYAQAAGJKCFQAAgCFZEgwAADA4S4IBAABgIApWAACAwXX35K95quqMqvpIVV1aVWdvcv2bqurCqtpbVf92f35vBSsAAAAHpKp2JHldkm9PcmqSs6rq1A0fuyLJ85P89v7e1zOsAAAAHKjTk1za3ZclSVWdk+RpSf5+3we6+2Nr11b296YKVgAAgMHdBYYuPTDJleve70ny2AO9qSXBAAAAzFVVO6tq97rXzvWXN/mRA66ydVgBAACYq7t3Jdm1xeU9SR607v0JSa460O9UsAIAAAyux18SfEGSU6rqpCT/nOTMJM8+0JtaEgwAAMAB6e69SV6Y5J1JPpTkd7v7kqp6ZVU9NUmq6jFVtSfJv0vy+qq6ZN59dVgBAAAGtz/7oE6tu89Lct6Gcy9fd3xBVpcK7zcdVgAAAIakYAUAAGBIlgQDAAAM7i6wD+tC6LACAAAwpJkd1qo6dG3aEwAAABO5KwxdWoR5Hdb3b0sKAAAA2GBewVp35qZVtbOqdlfV7ptu+cyduQUAAABLbt7QpeOr6qVbXezuX9zi/K4ku5Lkfvf8quXsXQMAABwkyzp0aV7BuiPJUbmTnVYAAAC4s+YVrB/v7lduSxIAAAA21UvaYV3IM6wAAABwoOYVrP9l30FVnbT+QlV910ISAQAAQOYXrGevO37bhms/dZCzAAAAsImV7slfU7gjS4I3Lg+2XBgAAICFmTd0qbc43uw9AAAAC7CsQ5fmFawnV9W5We2m7jvO2vuTtv4xAAAAODDzCtanrTv+hQ3XNr4HAACAg2Zmwdrd79l3XFXHr5371KJDAQAA8EVTDT2a2syhS7Xq/66qq5N8OMk/VNWnqurl2xMPAACAZTVvSvCLk3xjksd09727+15JHpvkcVX1koWnAwAAID3Af6Ywr2B9XpKzuvuj+05092VJvmftGgAAACzEvIL1sO6+euPJtedYD1tMJAAAAJg/JfiWO3kNAACAg2RZhy7NK1gfWVWf3eR8JTliAXkAAAAgyfxtbXZsVxAAAABYb16HFQAAgIlNNaV3avOGLgEAAMAkdFgBAAAGt6xDl3RYAQAAGJKCFQAAgCFZEgwAADA4Q5cAAABgIDqsAAAAg+temTrCJBZesN5w6+cX/RV3GR98xm9NHWEYzz32kVNHGMZvXHvh1BGG8Zmbbpg6wjAOPWTH1BGGcLdDD5s6wjAefexJU0cYxns/+aGpIwzjzZ/2vyHc3lnHf93UEeCgsSQYAACAIVkSDAAAMLgVQ5cAAABgHDqsAAAAg+vWYQUAAIBhKFgBAAAYkiXBAAAAgzN0CQAAAAaiwwoAADA4Q5cAAABgIApWAAAAhmRJMAAAwOBWLAkGAACAcShYAQAAGJIlwQAAAINr+7ACAADAOHRYAQAABmcfVgAAABiIghUAAIAhWRIMAAAwuBVDlwAAAGAcOqwAAACDM3QJAAAABqJgBQAAYEiWBAMAAAxuxZJgAAAAGMfMDmtV/fdZ17v7RQc3DgAAABst69CleUuCfyjJB5P8bpKrktT+3LSqdibZmSSHH3ZcDj306APJCAAAwBKaV7A+IMm/S/LdSfYmeWuSt3X3tbN+qLt3JdmVJPc48sTl/KsAAAAADsjMZ1i7+5ru/p/d/fgkz09ybJJLquq52xEOAACAZCU9+WsK+zUluKq+NslZSZ6U5B1JPrDIUAAAADBv6NIrkjw5yYeSnJPkZd29dzuCAQAAsMrQpc39dJLLkjxy7fWqqkpWhy91d3/NYuMBAACwrOYVrCdtSwoAAADYYGbB2t2Xb1cQAAAANrdiSfDtVdX1yZeMg+okVyc5P8mPd/c1C8wGAADAEpvXYT1647mquldWt7j5n1ndoxUAAIAF6om2lZnazH1YN9Pd13b3LyV56ALyAAAAQJI7UbAm+f/bu/cYucoyjuPfHwVJFVAKCEEIlRIslruXECgKChEMKBBMW0EoIRSjRMstiKCiTRSBigICwQulUWgRIsGKBAnUgGIQShEKCBYQUC5CES02XMrjH+87ntPT2d3p7tzn90k2u+c9ZybPPHsu73ve97yDpA1o8DtczczMzMzMzEZjpGdYj6hTvCkwDbiuJRGZmZmZmZnZGjzpUn2HVpYDeAn4QUT8ujUhmZmZmZmZmY086dJx7QrEzMzMzMzMrGykIcFfH2Z1RMScJsdjZmZmZmZmFeEhwXW9WqfsHcDxwGaAG6xmZmZmZmbWEiMNCZ5b+1vSxsCXgeOABcDcoV5nZmZmZmZmzTOo38M64lfTSJoAnAIcBVwF7BkRL7c6MDMzMzMzMxtsIz3Dej5wBHAFsEtErGxLVGZmZmZmZjbwRuphPRV4DTgbOEtSrVykSZc2aWFsZmZmZmZmhiddqisi1mtXIGZmZmZmZmZlIz7DamZmZmZmZp01qD2s7kE1MzMzMzOzruQGq5mZmZmZmXUlDwk2MzMzMzPrcoM5INg9rGZmZmZmZtalNCgP70qaFRFXdDqObuBcFJyLgnNRcC4S56HgXBSci4JzUXAuCs5FwbmwZhikHtZZnQ6gizgXBeei4FwUnIvEeSg4FwXnouBcFJyLgnNRcC5szAapwWpmZmZmZmY9xA1WMzMzMzMz60qD1GD1+PmCc1FwLgrORcG5SJyHgnNRcC4KzkXBuSg4FwXnwsZsYCZdMjMzMzMzs94ySD2sZmZmZmZm1kPcYDUzMzMzM7Ou1HMNVkmLJX2iUjZb0k2SVklaWvo5Jq9/UtIDkv4s6XeStiu9dnXe9n5JSyTt3e7PNFqSQtLc0vJpks4pLc+S9Ej+uVvS1NK6JyVtXlreT9Ki/PdMSW9J2rW0/kFJE1v8kVpO0raSnpA0IS9vmpe3G+m1vUzS4Xl/mZyXJ+bj5T5JD+f949jS9jMl/TMfGw9JOqFz0TfXuuQir3tG0nqV91gq6cOdiH+sJG0laYGk5fl/e5OkHSVNkXSbpEclPSbpa5KUXzPsOaF6PulFpWvBg5J+Ientdcp/JeldknYpXWdW5HPIUkm3dvpz2Oityz5Qes2oj5teNcrrySWdi7i5SvvDslx3PKV2jch1qVe0Zl10Wunv5yT9vbT8tk5/ntHQMPVPSfMkHVnZfmX+PTG/dk5p3eaS3uinfcSar+carMA1wPRK2XTgO8DyiNi99DO/tM3+EbErsBg4u1S+Km+7G3Bmfp9e8RpwRL2KoqRDgBOBqRExGfg8cLWkrRp872eAs5oWaZeIiKeBy4Bzc9G5wBUR8bfORdUWM4A7WfPYWR4Re0TETrn8ZEnHldYvjIjdgf2Ab0vasm3RtlbDuYiIJ4GngX1rG+ZK2sYRcXcbY26KXJH+JbA4IiZFxPuBrwJbAjcC50bEjsBuwN7AF0ov78tzQkntWrAz8DrpnFktXwF8MSIeqF1nSHk7PS8f0KHYrTka3gcAJI1nMI+b0VxP+kltf5gCHAh8EvhGaf0dlbrowtL54nLgwtK61zvxAZpgyPpnAx4HDiktfwZY1pSorG/1YoP1OuAQSRtCulsDbE26KDTiLuA9Q6zbBHh5jPG105uk2ddOrrPuDFIl6kWAiFgCXEW+0DZgETBF0vuaEWiXuRDYS9JsYCowd4Tte5qkjYB9gONZ+2YPABHxOHAK8KU6614AlgM93ws9ylxUb5JNz2W9aH/gjYi4vFYQEUuBHYHfR8Qtuey/wEnAV0qv7edzQtUdwA51yoe7flh/aWQf+CwDdtyM9XrSb/L1cRZwUq1nfUAMV/8cySrgYUkfzMvTgGubFZj1p55rsEbES8DdwEG5aDqwEAhgUmUYxr513uIg4IbS8vi87SPAj4E5dV7TzX4IHCXpnZXyKcC9lbJ7cnkj3gLOI/W+9JWIeAM4ndRwnd3DdzgbdRhwc0Q8CqyQtOcQ2y0BJlcLJW0PbA/8tXUhts1ocnEtcJik9fPyNGBBa8NsmZ1Z+7wAdc4XEbEc2EjSJrmob88JZfn/fDDwQKV8HPBxUo+a9bF12AcG8bgZ0/WkH+UG+nrAu3PRvpW66KQOhtdKQ9U/G7EAmC5pG2A18I+mRmZ9p+carFm5x6Pc21EdEnxH6TW3S3oBOAC4ulReG9oxmdSYnd9Ld8ki4t/AfBq7kylSw57S7zXerrJ8Nakn8r2jj7BrHQw8S6rA97sZFA2sBXm5nup+P03SUtLxdWJErGhRfO20zrmIiOdIw5U+Lml3Ug/lgy2Nsv3K54aqcnk/nxPG5/39HuAp4CeV8peACcBvOxSftd667gODeNyM9nrS78qftzokeHnHomqhYeqfjdQvbyYNp55B6nQyG9b6I2/SlW4Avpfv7I2PiCUNTGKwP/AqMA/4Fmm4yhoi4q48Hn8L4IVmBtxi3yfdzbyyVPYQ8AHgtlLZnrkc0oV3U+DFvDyh9DcAEfFmfqj+jBbE3DG50XEgsBdwp6QFEfFsh8NqCUmbAR8DdpYUwDjShePSOpvvATxcWl4YESe1Psr2GGMuajfJnqd3hwNDangfOUT5R8oFuWd9ZUT8p3YPr1/PCdmq/IxZ3fLci7CI9FjFRe0NzdpkXfeBgTpuxngO7Vv5f76aVG/cqcPhtFu9+metfgmA0iSX1frl65LuBU4ljVQ4tPWhWi/ryR7WiFhJmjzpp6xD5TEiVgGzgWPyAbSGPJnKONLB1jNyz9e1pGdKas4DvpsvMLVG2kyKC8ti4HN53TjgaOD2Om8/j9QrvUXzI2+/3Ht+GWko8FPA+cAFnY2qpY4E5kfEdhExMSK2BZ4AtilvlG/4XABc3PYI22csubieNLFGLw8HhnQDa0OVZn2W9CHgMWCqpANy2XhShfy8Ou8xjz46JzQqIl4h9SScJmmDTsdj7VdnH/g5g3Xc+HpSIWkL0kRKl0TEUL3tfWuI+udi0git2gzIM6lfv5wLnJEf9TMbVk82WLNrSDPylSuP1WdY600g82x+bW3yodozrEtJwxKOjYjVrQ6+BeYC/5+tLSJuJDXo/5Cfz/0RcHSpJ3EOsIOk+4H7SM8n/qz6pvn5zosons3odScAT0VEbUjXpcBkSR/tYEytNIM0K2zZ9aTnqSYpfw0B6YJzcURcWX2DPjLqXETEv4A/As9HxBPtCrjZcoXqcOBApa+1WQacQ3p+6NPA2ZL+Qnp270/AWl8zMMQ5YX3SrJF9LSLuA+5niMlmBoXSVyFt3ek4OqG8D+Sb4GM5bnrNaM+h/XZ+qNUblwG3ArcA3yytrz7DWm9USz+p1j8XkSYtuzfXrfehzuiCiFgWEVe1LUrraRrAG0JmZtYkuYdhaUR49lwzW4ukC4HHIqLe0GEzsxH1cg+rmZl1kKRPke6kn9npWMys+0j6DbArafi0mdmouIfVzMzMzMzMupJ7WM3MzMzMzKwrucFqZmZmZmZmXckNVjMzMzMzM+tKbrCamZmZmZlZV3KD1czMzMzMzLrS/wD+ulKkeR+YggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# heatmap of tags matrix\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequent tags\n",
    "# filter the df to get P(t2, t1) > 0.5\n",
    "\n",
    "\n",
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 5:  Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> The steps are as follows:\n",
    "\n",
    "1. Given a sequence of words\n",
    "2. iterate through the sequence\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained in step 3 above.\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the computed probabilities P(w, tag) and P(t2, t1) to assign tags to each word in the document. We'll run through each word w and compute P(tag/w)=P(w/tag).P(tag) for each tag in the tag set, and then assign the tag having the max P(tag/w).\n",
    "\n",
    "We'll store the assigned tags in a list of tuples, similar to the list 'train_tagged_words'. Each tuple will be a (token, assigned_tag). As we progress further in the list, each tag to be assigned will use the tag of the previous token.\n",
    "\n",
    "Note: P(tag|start) = P(tag|'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> Function for Vanilla Viterbi Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    \n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 6: Evaluating on Test Set\n",
    "    \n",
    " Testing Vanilla Viterbi Algorithm on sampled test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random value : \n",
      " [113, 30, 2, 24, 150]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_run 0th position value : \n",
      " [('The', 'DET'), ('Contra', 'NOUN'), ('military', 'ADJ'), ('command', 'NOUN'), (',', '.'), ('in', 'ADP'), ('a', 'DET'), ('statement', 'NOUN'), ('from', 'ADP'), ('Honduras', 'NOUN'), (',', '.'), ('said', 'VERB'), ('0', 'X'), ('Sandinista', 'NOUN'), ('troops', 'NOUN'), ('had', 'VERB'), ('launched', 'VERB'), ('a', 'DET'), ('major', 'ADJ'), ('offensive', 'NOUN'), ('against', 'ADP'), ('the', 'DET'), ('rebel', 'NOUN'), ('forces', 'NOUN'), ('.', '.')]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_run_base 0th to 5th position value : \n",
      " [('The', 'DET'), ('Contra', 'NOUN'), ('military', 'ADJ'), ('command', 'NOUN'), (',', '.')]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words 0th to 5th position value : \n",
      " ['The', 'Contra', 'military', 'command', ',']\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "print(\"random value : \\n\" , rndom)\n",
    "print(\"*\"*100, \" \\n\\n\")\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "print(\"test_run 0th position value : \\n\" , test_run[0])\n",
    "print(\"*\"*100, \" \\n\\n\")\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "print(\"test_run_base 0th to 5th position value : \\n\" , test_run_base[0 : 5])\n",
    "print(\"*\"*100, \" \\n\\n\")\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "print(\"test_tagged_words 0th to 5th position value : \\n\" , test_tagged_words[0 : 5])\n",
    "print(\"*\"*100, \" \\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(viterbi_function , test_tagged_words_val, test_run_base_val, model_name = \"Model \"):\n",
    "    # tagging the test sentences\n",
    "    start = time.time()\n",
    "    tagged_seq = viterbi_function(test_tagged_words_val)\n",
    "    end = time.time()\n",
    "    difference = end-start\n",
    "    \n",
    "    print(\"Time taken in seconds: \", difference)\n",
    "    print(\"*\"*100, \" \\n\\n\")\n",
    "    \n",
    "    \n",
    "    # accuracy\n",
    "    check = [i for i, j in zip(tagged_seq, test_run_base_val) if i == j] \n",
    "    accuracy = len(check)/len(tagged_seq) * 100\n",
    "    \n",
    "    print(model_name, ' Algorithm Accuracy: ',accuracy)\n",
    "    print(\"*\"*100, \" \\n\\n\")\n",
    "    \n",
    "    #check the incorrectly tagged words and accuracy\n",
    "    check_incorrect = [j for i, j in enumerate(zip(tagged_seq, test_run_base_val)) if j[0] != j[1]]\n",
    "    accuracy_incorrected = len(check_incorrect)/len(tagged_seq) * 100\n",
    "    \n",
    "    print(model_name,' Algorithm Incorrected Accuracy: ',accuracy_incorrected)\n",
    "    print(\"*\"*100, \" \\n\\n\")\n",
    "    \n",
    "    print(\"test_tagged_words : \\n\",test_tagged_words_val)\n",
    "    print(\"*\"*100, \" \\n\\n\")\n",
    "    \n",
    "    print(\"Incorrect test_tagged_words : \\n\",check_incorrect)\n",
    "    \n",
    "    return [model_name, accuracy, accuracy_incorrected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model Name, Correct Accuracy, Incorrect Accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df = pd.DataFrame( columns = [\"Model Name\", \"Correct Accuracy\", \"Incorrect Accuracy\"])\n",
    "model_detail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.30980610847473\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi  Algorithm Accuracy:  91.1504424778761\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi  Algorithm Incorrected Accuracy:  8.849557522123893\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words : \n",
      " ['The', 'Contra', 'military', 'command', ',', 'in', 'a', 'statement', 'from', 'Honduras', ',', 'said', '0', 'Sandinista', 'troops', 'had', 'launched', 'a', 'major', 'offensive', 'against', 'the', 'rebel', 'forces', '.', '*-1', 'Bucking', 'the', 'market', 'trend', ',', 'an', 'issue', 'of', '$', '130', 'million', '*U*', 'general', 'obligation', 'distributable', 'state', 'aid', 'bonds', 'from', 'Detroit', ',', 'Mich.', ',', 'apparently', 'drew', 'solid', 'investor', 'interest', '.', 'Ralston', 'said', '0', 'its', 'Eveready', 'battery', 'unit', 'was', 'hurt', '*-1', 'by', 'continuing', 'economic', 'problems', 'in', 'South', 'America', '.', 'I', 'feel', 'pretty', 'good', 'about', 'it', '.', 'Mr.', 'Felten', 'said', ',', '``', 'We', 'got', 'what', '*T*-252', 'amounted', 'to', 'a', 'parking', 'ticket', ',', 'and', 'by', '*-1', 'complaining', 'about', 'it', ',', 'we', 'ended', 'up', 'with', 'a', 'sizable', 'fine', 'and', 'suspension', '.', \"''\"]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Incorrect test_tagged_words : \n",
      " [(('Contra', 'VERB'), ('Contra', 'NOUN')), (('command', 'VERB'), ('command', 'NOUN')), (('Honduras', 'VERB'), ('Honduras', 'NOUN')), (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')), (('offensive', 'VERB'), ('offensive', 'NOUN')), (('rebel', 'VERB'), ('rebel', 'NOUN')), (('forces', 'VERB'), ('forces', 'NOUN')), (('Eveready', 'VERB'), ('Eveready', 'NOUN')), (('*T*-252', 'VERB'), ('*T*-252', 'X')), (('up', 'ADV'), ('up', 'PRT'))]\n"
     ]
    }
   ],
   "source": [
    "model_detail = check_accuracy(Viterbi, test_tagged_words, test_run_base,\"Vanilla Viterbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Name  Correct Accuracy  Incorrect Accuracy\n",
       "0  Vanilla Viterbi           91.1504              8.8496"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.loc[0] = model_detail\n",
    "model_detail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time :  2.6626369953155518\n",
      "[('Google', 'VERB'), ('and', 'CONJ'), ('Twitter', 'VERB'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'VERB'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'VERB'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "## Testing\n",
    "sentence_test1 = 'Google and Twitter made a deal in 2015 that gave Google access to Twitter\\'s firehose.'\n",
    "words1 = word_tokenize(sentence_test1)\n",
    "\n",
    "start = time.time()\n",
    "tagged_seq1 = Viterbi(words1)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"time : \", difference)\n",
    "print(tagged_seq1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Step 7:  Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Blue'> Different Types of techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use Lexical techniqies on the same data to see if we get better <br>\n",
    "2. Use Rule Base  techniqies on the same data to see if we get better <br>\n",
    "3. Use Combine techniqies on the same data to see if we get better <br>\n",
    "4. Use these to tag unknown words, then see if we get better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'orange'> Unigram Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_unigram_tagger :  90.6999415090661\n"
     ]
    }
   ],
   "source": [
    "# Lexicon (or unigram tagger)\n",
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "accuracy_unigram_tagger = unigram_tagger.evaluate(test_set)  * 100\n",
    "print(\"accuracy_unigram_tagger : \", accuracy_unigram_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'orange'> Bigram Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_bigram_tagger :  21.778124390719437\n"
     ]
    }
   ],
   "source": [
    "# Lexicon (or bigram tagger)\n",
    "bigram_tagger = nltk.BigramTagger(train_set)\n",
    "accuracy_bigram_tagger = bigram_tagger.evaluate(test_set)  * 100\n",
    "print(\"accuracy_bigram_tagger : \", accuracy_bigram_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'orange'> Trigram Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_trigram_tagger :  11.132774419964905\n"
     ]
    }
   ],
   "source": [
    "trigram_tagger = nltk.TrigramTagger(train_set)\n",
    "trigram_tagger.evaluate(test_set)\n",
    "accuracy_trigram_tagger = trigram_tagger.evaluate(test_set) * 100\n",
    "print(\"accuracy_trigram_tagger : \", accuracy_trigram_tagger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model Name  Correct Accuracy  Incorrect Accuracy\n",
       "0  Vanilla Viterbi           91.1504              8.8496\n",
       "1  Lexicon Unigram           90.6999              9.3001\n",
       "2   Lexicon Bigram           21.7781             78.2219\n",
       "3  Lexicon Trigram           11.1328             88.8672"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_details = [\"Lexicon Unigram\", accuracy_unigram_tagger, 100 - accuracy_unigram_tagger]\n",
    "bigram_details =  [\"Lexicon Bigram\", accuracy_bigram_tagger, 100 - accuracy_bigram_tagger]\n",
    "trigram_details = [\"Lexicon Trigram\", accuracy_trigram_tagger, 100 - accuracy_trigram_tagger]\n",
    "\n",
    "model_detail_df.loc[1] = unigram_details\n",
    "model_detail_df.loc[2] = bigram_details\n",
    "model_detail_df.loc[3] = trigram_details\n",
    "model_detail_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'orange'> Rule Based Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "# example from the NLTK book\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),              # gerund\n",
    "    (r'.*ed$', 'VBD'),               # past tense\n",
    "    (r'.*es$', 'VBZ'),               # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),              # modals\n",
    "    (r'.*\\'s$', 'NN$'),              # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
    "    (r'.*', 'NN')                    # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_rule_base_tagger :  0.0\n"
     ]
    }
   ],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "accuracy_rule_base_tagger = regexp_tagger.evaluate(test_set)  * 100\n",
    "print(\"accuracy_rule_base_tagger : \", accuracy_rule_base_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'orange'> Combining Taggers :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try combining the taggers created above. We saw that the rule-based tagger by itself is quite ineffective since we've only written a handful of rules. However, if we could combine the lexicon and the rule-based tagger, we can potentially create a tagger much better than any of the individual ones.\n",
    "\n",
    "NLTK provides a convenient way to combine taggers using the 'backup' argument. In the following code, we create a regex tagger which is used as a backup tagger to the lexicon tagger, i.e. when the tagger is not able to tag using the lexicon (in case of a new word not in the vocabulary), it uses the rule-based tagger. \n",
    "\n",
    "Also, note that the rule-based tagger itself is backed up by the tag 'NN'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_combine_lexicon_rule_tagger :  90.6999415090661\n"
     ]
    }
   ],
   "source": [
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "combine_lexicon_tagger = nltk.UnigramTagger(train_set, backoff = rule_based_tagger) # lexicon backed up by the rule-based tagger\n",
    "\n",
    "accuracy_combine_lexicon_rule_tagger = combine_lexicon_tagger.evaluate(test_set)  * 100\n",
    "\n",
    "print(\"accuracy_combine_lexicon_rule_tagger : \",accuracy_combine_lexicon_rule_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_combine_lexicon_bigram_rule_tagger :  91.0898810684344\n"
     ]
    }
   ],
   "source": [
    "# Bigram and Trigram tagger\n",
    "combine_bigram_tagger = nltk.BigramTagger(train_set,backoff = combine_lexicon_tagger)\n",
    "\n",
    "accuracy_combine_lexicon_bigram_rule_tagger = combine_bigram_tagger.evaluate(test_set)  * 100\n",
    "\n",
    "print(\"accuracy_combine_lexicon_bigram_rule_tagger : \", accuracy_combine_lexicon_bigram_rule_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_trigram_tagger :  91.10937804640281\n"
     ]
    }
   ],
   "source": [
    "combine_trigram_tagger = nltk.TrigramTagger(train_set, backoff = combine_bigram_tagger)\n",
    "\n",
    "accuracy_combine_lexicon__unigram_bigram_rule_tagger = combine_trigram_tagger.evaluate(test_set)  * 100\n",
    "\n",
    "print(\"accuracy_trigram_tagger : \", accuracy_combine_lexicon__unigram_bigram_rule_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model Name  Correct Accuracy  \\\n",
       "0                                   Vanilla Viterbi           91.1504   \n",
       "1                                   Lexicon Unigram           90.6999   \n",
       "2                                    Lexicon Bigram           21.7781   \n",
       "3                                   Lexicon Trigram           11.1328   \n",
       "4                                         Rule Base            0.0000   \n",
       "5                Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6          Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7  Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "\n",
       "   Incorrect Accuracy  \n",
       "0              8.8496  \n",
       "1              9.3001  \n",
       "2             78.2219  \n",
       "3             88.8672  \n",
       "4            100.0000  \n",
       "5              9.3001  \n",
       "6              8.9101  \n",
       "7              8.8906  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_base_details = [\"Rule Base\", accuracy_rule_base_tagger, 100 - accuracy_rule_base_tagger]\n",
    "combine_lexicon_rule_details =  [\"Combine Lexicon Unigram Rule Base \", accuracy_combine_lexicon_rule_tagger, 100 - accuracy_combine_lexicon_rule_tagger]\n",
    "combine_lexicon_bigram_rule_details = [\"Combine Lexicon Unigram Bigram Rule Base\", accuracy_combine_lexicon_bigram_rule_tagger, 100 - accuracy_combine_lexicon_bigram_rule_tagger]\n",
    "combine_lexicon_unigram_bigram_rule_details = [\"Combine Lexicon Unigram Bigram Trigram Rule Base\", accuracy_combine_lexicon__unigram_bigram_rule_tagger, 100 - accuracy_combine_lexicon__unigram_bigram_rule_tagger]\n",
    "\n",
    "model_detail_df.loc[4] = rule_base_details\n",
    "model_detail_df.loc[5] = combine_lexicon_rule_details\n",
    "model_detail_df.loc[6] = combine_lexicon_bigram_rule_details\n",
    "model_detail_df.loc[7] = combine_lexicon_unigram_bigram_rule_details\n",
    "model_detail_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting marginally better, but not by much. <br>\n",
    "Next lets see if we can use this for the unknown words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Green'> Optimization\n",
    "\n",
    "We can see that all of unknown words have been tagged as 'NUM' as 'NUM' is the first tag in tag list and is assigned if unknown word is encountered (emission probability =0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> A)Viterbi Modification-Technique I\n",
    "\n",
    "* **First solution for unknown words**: assign based on transition probabilities only in case of unknown words as emission probability for unknown word is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use transition probability of tags when emission probability is zero (in case of unknown words)\n",
    "\n",
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] #todo \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.67174744606018\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 1  Algorithm Accuracy:  94.69026548672566\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 1  Algorithm Incorrected Accuracy:  5.3097345132743365\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words : \n",
      " ['The', 'Contra', 'military', 'command', ',', 'in', 'a', 'statement', 'from', 'Honduras', ',', 'said', '0', 'Sandinista', 'troops', 'had', 'launched', 'a', 'major', 'offensive', 'against', 'the', 'rebel', 'forces', '.', '*-1', 'Bucking', 'the', 'market', 'trend', ',', 'an', 'issue', 'of', '$', '130', 'million', '*U*', 'general', 'obligation', 'distributable', 'state', 'aid', 'bonds', 'from', 'Detroit', ',', 'Mich.', ',', 'apparently', 'drew', 'solid', 'investor', 'interest', '.', 'Ralston', 'said', '0', 'its', 'Eveready', 'battery', 'unit', 'was', 'hurt', '*-1', 'by', 'continuing', 'economic', 'problems', 'in', 'South', 'America', '.', 'I', 'feel', 'pretty', 'good', 'about', 'it', '.', 'Mr.', 'Felten', 'said', ',', '``', 'We', 'got', 'what', '*T*-252', 'amounted', 'to', 'a', 'parking', 'ticket', ',', 'and', 'by', '*-1', 'complaining', 'about', 'it', ',', 'we', 'ended', 'up', 'with', 'a', 'sizable', 'fine', 'and', 'suspension', '.', \"''\"]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Incorrect test_tagged_words : \n",
      " [(('command', 'VERB'), ('command', 'NOUN')), (('Honduras', 'DET'), ('Honduras', 'NOUN')), (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')), (('Eveready', 'VERB'), ('Eveready', 'NOUN')), (('*T*-252', 'VERB'), ('*T*-252', 'X')), (('up', 'ADV'), ('up', 'PRT'))]\n"
     ]
    }
   ],
   "source": [
    "model_detail_1 = check_accuracy(Viterbi_1,test_tagged_words,test_run_base,\"Vanilla Viterbi 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vanilla Viterbi 1</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>5.3097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model Name  Correct Accuracy  \\\n",
       "0                                   Vanilla Viterbi           91.1504   \n",
       "1                                   Lexicon Unigram           90.6999   \n",
       "2                                    Lexicon Bigram           21.7781   \n",
       "3                                   Lexicon Trigram           11.1328   \n",
       "4                                         Rule Base            0.0000   \n",
       "5                Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6          Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7  Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "8                                 Vanilla Viterbi 1           94.6903   \n",
       "\n",
       "   Incorrect Accuracy  \n",
       "0              8.8496  \n",
       "1              9.3001  \n",
       "2             78.2219  \n",
       "3             88.8672  \n",
       "4            100.0000  \n",
       "5              9.3001  \n",
       "6              8.9101  \n",
       "7              8.8906  \n",
       "8              5.3097  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.loc[8] = model_detail_1\n",
    "model_detail_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> Adding Tag occurance probability weights: \n",
    "\n",
    "we will apply weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words.\n",
    "\n",
    "This scheme will also take into account that some POS tags are more likely to occur as compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VERB', 0.1351167488251855),\n",
       " ('NOUN', 0.2862674913916711),\n",
       " ('X', 0.06576867928872701),\n",
       " ('ADP', 0.0978889970381069),\n",
       " ('ADV', 0.031597015081582885),\n",
       " ('CONJ', 0.02251248076862696),\n",
       " ('PRT', 0.03176447193527793),\n",
       " ('.', 0.11641391147812072),\n",
       " ('PRON', 0.0273373313657153),\n",
       " ('ADJ', 0.06351847781719991),\n",
       " ('DET', 0.08666938784053921),\n",
       " ('NUM', 0.035145007169246546)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a list containing tuples of POS tags and POS tag occurance probability, based on training data\n",
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.81160020828247\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 2  Algorithm Accuracy:  95.57522123893806\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 2  Algorithm Incorrected Accuracy:  4.424778761061947\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words : \n",
      " ['The', 'Contra', 'military', 'command', ',', 'in', 'a', 'statement', 'from', 'Honduras', ',', 'said', '0', 'Sandinista', 'troops', 'had', 'launched', 'a', 'major', 'offensive', 'against', 'the', 'rebel', 'forces', '.', '*-1', 'Bucking', 'the', 'market', 'trend', ',', 'an', 'issue', 'of', '$', '130', 'million', '*U*', 'general', 'obligation', 'distributable', 'state', 'aid', 'bonds', 'from', 'Detroit', ',', 'Mich.', ',', 'apparently', 'drew', 'solid', 'investor', 'interest', '.', 'Ralston', 'said', '0', 'its', 'Eveready', 'battery', 'unit', 'was', 'hurt', '*-1', 'by', 'continuing', 'economic', 'problems', 'in', 'South', 'America', '.', 'I', 'feel', 'pretty', 'good', 'about', 'it', '.', 'Mr.', 'Felten', 'said', ',', '``', 'We', 'got', 'what', '*T*-252', 'amounted', 'to', 'a', 'parking', 'ticket', ',', 'and', 'by', '*-1', 'complaining', 'about', 'it', ',', 'we', 'ended', 'up', 'with', 'a', 'sizable', 'fine', 'and', 'suspension', '.', \"''\"]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Incorrect test_tagged_words : \n",
      " [(('command', 'VERB'), ('command', 'NOUN')), (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')), (('Eveready', 'VERB'), ('Eveready', 'NOUN')), (('*T*-252', 'VERB'), ('*T*-252', 'X')), (('up', 'ADV'), ('up', 'PRT'))]\n"
     ]
    }
   ],
   "source": [
    "model_detail_2 = check_accuracy(Viterbi_2,test_tagged_words,test_run_base,\"Vanilla Viterbi 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vanilla Viterbi 1</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>5.3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vanilla Viterbi 2</td>\n",
       "      <td>95.5752</td>\n",
       "      <td>4.4248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model Name  Correct Accuracy  \\\n",
       "0                                   Vanilla Viterbi           91.1504   \n",
       "1                                   Lexicon Unigram           90.6999   \n",
       "2                                    Lexicon Bigram           21.7781   \n",
       "3                                   Lexicon Trigram           11.1328   \n",
       "4                                         Rule Base            0.0000   \n",
       "5                Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6          Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7  Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "8                                 Vanilla Viterbi 1           94.6903   \n",
       "9                                 Vanilla Viterbi 2           95.5752   \n",
       "\n",
       "   Incorrect Accuracy  \n",
       "0              8.8496  \n",
       "1              9.3001  \n",
       "2             78.2219  \n",
       "3             88.8672  \n",
       "4            100.0000  \n",
       "5              9.3001  \n",
       "6              8.9101  \n",
       "7              8.8906  \n",
       "8              5.3097  \n",
       "9              4.4248  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.loc[9] = model_detail_2\n",
    "model_detail_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thus, we see that we have got a much better accuracy by using weighted transition probabilties.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following list of words have been correctly POS tagged by Viterbi_1 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "Contra:correctly tagged as NOUN\n",
    "Honduras:correctly tagged as NOUN\n",
    "complaining: correctly tagged as VERB\n",
    "Bucking: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> B) Viterbi Modification-Technique II\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **second solution for unknown words:** \n",
    "\n",
    "* backoff to rule based tagger in case of unknown words.\n",
    "* we further observe that POS tag 'X' can be easily encapsulated in regex rule, so we extract it only based on ruled based tagged.\n",
    "\n",
    "Let's define a rule based tagger as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification in Viterbi Algorithm : Backoff to rule based tagger in case unknown word is encountered.\n",
    "def Viterbi_3(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "       \n",
    "        \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "            \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.08884835243225\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 3  Algorithm Accuracy:  97.34513274336283\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 3  Algorithm Incorrected Accuracy:  2.6548672566371683\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words : \n",
      " ['The', 'Contra', 'military', 'command', ',', 'in', 'a', 'statement', 'from', 'Honduras', ',', 'said', '0', 'Sandinista', 'troops', 'had', 'launched', 'a', 'major', 'offensive', 'against', 'the', 'rebel', 'forces', '.', '*-1', 'Bucking', 'the', 'market', 'trend', ',', 'an', 'issue', 'of', '$', '130', 'million', '*U*', 'general', 'obligation', 'distributable', 'state', 'aid', 'bonds', 'from', 'Detroit', ',', 'Mich.', ',', 'apparently', 'drew', 'solid', 'investor', 'interest', '.', 'Ralston', 'said', '0', 'its', 'Eveready', 'battery', 'unit', 'was', 'hurt', '*-1', 'by', 'continuing', 'economic', 'problems', 'in', 'South', 'America', '.', 'I', 'feel', 'pretty', 'good', 'about', 'it', '.', 'Mr.', 'Felten', 'said', ',', '``', 'We', 'got', 'what', '*T*-252', 'amounted', 'to', 'a', 'parking', 'ticket', ',', 'and', 'by', '*-1', 'complaining', 'about', 'it', ',', 'we', 'ended', 'up', 'with', 'a', 'sizable', 'fine', 'and', 'suspension', '.', \"''\"]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Incorrect test_tagged_words : \n",
      " [(('command', 'VERB'), ('command', 'NOUN')), (('drew', 'NOUN'), ('drew', 'VERB')), (('up', 'ADV'), ('up', 'PRT'))]\n"
     ]
    }
   ],
   "source": [
    "model_detail_3 = check_accuracy(Viterbi_3,test_tagged_words,test_run_base,\"Vanilla Viterbi 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vanilla Viterbi 1</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>5.3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vanilla Viterbi 2</td>\n",
       "      <td>95.5752</td>\n",
       "      <td>4.4248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vanilla Viterbi 3</td>\n",
       "      <td>97.3451</td>\n",
       "      <td>2.6549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Correct Accuracy  \\\n",
       "0                                    Vanilla Viterbi           91.1504   \n",
       "1                                    Lexicon Unigram           90.6999   \n",
       "2                                     Lexicon Bigram           21.7781   \n",
       "3                                    Lexicon Trigram           11.1328   \n",
       "4                                          Rule Base            0.0000   \n",
       "5                 Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6           Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7   Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "8                                  Vanilla Viterbi 1           94.6903   \n",
       "9                                  Vanilla Viterbi 2           95.5752   \n",
       "10                                 Vanilla Viterbi 3           97.3451   \n",
       "\n",
       "    Incorrect Accuracy  \n",
       "0               8.8496  \n",
       "1               9.3001  \n",
       "2              78.2219  \n",
       "3              88.8672  \n",
       "4             100.0000  \n",
       "5               9.3001  \n",
       "6               8.9101  \n",
       "7               8.8906  \n",
       "8               5.3097  \n",
       "9               4.4248  \n",
       "10              2.6549  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.loc[10] = model_detail_3\n",
    "model_detail_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi 3 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi 3 as compared to Viterbi_1\n",
    "\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Blue'> further modification in Viterb 4:\n",
    " \n",
    " \n",
    "We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags.\n",
    "\n",
    "So, first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified Viterbi\n",
    "def Viterbi_4(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        \n",
    "      \n",
    "        # getting state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            \n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "                \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.112403631210327\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 4  Algorithm Accuracy:  98.23008849557522\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Vanilla Viterbi 4  Algorithm Incorrected Accuracy:  1.7699115044247788\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "test_tagged_words : \n",
      " ['The', 'Contra', 'military', 'command', ',', 'in', 'a', 'statement', 'from', 'Honduras', ',', 'said', '0', 'Sandinista', 'troops', 'had', 'launched', 'a', 'major', 'offensive', 'against', 'the', 'rebel', 'forces', '.', '*-1', 'Bucking', 'the', 'market', 'trend', ',', 'an', 'issue', 'of', '$', '130', 'million', '*U*', 'general', 'obligation', 'distributable', 'state', 'aid', 'bonds', 'from', 'Detroit', ',', 'Mich.', ',', 'apparently', 'drew', 'solid', 'investor', 'interest', '.', 'Ralston', 'said', '0', 'its', 'Eveready', 'battery', 'unit', 'was', 'hurt', '*-1', 'by', 'continuing', 'economic', 'problems', 'in', 'South', 'America', '.', 'I', 'feel', 'pretty', 'good', 'about', 'it', '.', 'Mr.', 'Felten', 'said', ',', '``', 'We', 'got', 'what', '*T*-252', 'amounted', 'to', 'a', 'parking', 'ticket', ',', 'and', 'by', '*-1', 'complaining', 'about', 'it', ',', 'we', 'ended', 'up', 'with', 'a', 'sizable', 'fine', 'and', 'suspension', '.', \"''\"]\n",
      "****************************************************************************************************  \n",
      "\n",
      "\n",
      "Incorrect test_tagged_words : \n",
      " [(('command', 'VERB'), ('command', 'NOUN')), (('up', 'ADV'), ('up', 'PRT'))]\n"
     ]
    }
   ],
   "source": [
    "model_detail_4 = check_accuracy(Viterbi_4,test_tagged_words,test_run_base,\"Vanilla Viterbi 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vanilla Viterbi 1</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>5.3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vanilla Viterbi 2</td>\n",
       "      <td>95.5752</td>\n",
       "      <td>4.4248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vanilla Viterbi 3</td>\n",
       "      <td>97.3451</td>\n",
       "      <td>2.6549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vanilla Viterbi 4</td>\n",
       "      <td>98.2301</td>\n",
       "      <td>1.7699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Correct Accuracy  \\\n",
       "0                                    Vanilla Viterbi           91.1504   \n",
       "1                                    Lexicon Unigram           90.6999   \n",
       "2                                     Lexicon Bigram           21.7781   \n",
       "3                                    Lexicon Trigram           11.1328   \n",
       "4                                          Rule Base            0.0000   \n",
       "5                 Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6           Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7   Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "8                                  Vanilla Viterbi 1           94.6903   \n",
       "9                                  Vanilla Viterbi 2           95.5752   \n",
       "10                                 Vanilla Viterbi 3           97.3451   \n",
       "11                                 Vanilla Viterbi 4           98.2301   \n",
       "\n",
       "    Incorrect Accuracy  \n",
       "0               8.8496  \n",
       "1               9.3001  \n",
       "2              78.2219  \n",
       "3              88.8672  \n",
       "4             100.0000  \n",
       "5               9.3001  \n",
       "6               8.9101  \n",
       "7               8.8906  \n",
       "8               5.3097  \n",
       "9               4.4248  \n",
       "10              2.6549  \n",
       "11              1.7699  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.loc[11] = model_detail_4\n",
    "model_detail_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#<font color = 'brown'>We observe that much better accuracy is obtained now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_4 as compared to vanilla Viterbi Algorithm:\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_4 as compared to Viterbi_1\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'>Step 8: Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_run_base = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'company', 'said', '0', 'it', 'is', 'in', 'the', 'process', 'of']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  891.9741384983063\n",
      "Viterbi Algorithm Accuracy:  92.12322090076039\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_4(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'Green'> Evaluating tagging on sample 'Test_sentences.txt' file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta',\n",
       " 'I would like to see flights from Denver to Philadelphia.',\n",
       " 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.',\n",
       " 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('Test_sentences.txt')\n",
    "text = f.read()\n",
    "sample_test_sent = text.splitlines()\n",
    "f.close()\n",
    "\n",
    "sample_test_sent = sample_test_sent[:-3]\n",
    "sample_test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android', 'is', 'a', 'mobile', 'operating', 'system', 'developed', 'by']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]\n",
    "sample_test_words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Android is a mobile operating system developed by Google. Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013. Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose. Twitter is an online news and social networking service on which users post and interact with messages known as tweets. Before entering politics, Donald Trump was a domineering businessman and a television personality. The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years. This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe. Show me the cheapest round trips from Dallas to Atlanta I would like to see flights from Denver to Philadelphia. Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco. NASA invited social media users to experience the launch of ICESAT-2 Satellite.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_words_string = \" \".join(sample_test_words)\n",
    "sample_test_words_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dic = {\"Viterbi\" : Viterbi, \"Viterbi 1\" : Viterbi_1 , \"Viterbi 2\" : Viterbi_2, \"Viterbi 4\" : Viterbi_4}\n",
    "\n",
    "def testing_unseen_data(model_list, sentence_test_val):\n",
    "    test_words = word_tokenize(sentence_test_val)\n",
    "    \n",
    "    for model_name, model in model_dic.items():\n",
    "        print(\"Model Name: \", model_name ,\"\\n\")\n",
    "        \n",
    "        test_tagged_sequence = model(test_words)\n",
    "        print(test_tagged_sequence, \"\\n\")\n",
    "        print(\"*\"*125)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  Viterbi \n",
      "\n",
      "[('Android', 'VERB'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'VERB'), ('.', '.'), ('Android', 'VERB'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'VERB'), ('worldwide', 'VERB'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'VERB'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'VERB'), ('.', '.'), ('Google', 'VERB'), ('and', 'CONJ'), ('Twitter', 'VERB'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'VERB'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'VERB'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.'), ('Twitter', 'VERB'), ('is', 'VERB'), ('an', 'DET'), ('online', 'VERB'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'VERB'), ('with', 'ADP'), ('messages', 'VERB'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'VERB'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'VERB'), ('.', '.'), ('The', 'DET'), ('2018', 'VERB'), ('FIFA', 'VERB'), ('World', 'NOUN'), ('Cup', 'VERB'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'VERB'), ('FIFA', 'VERB'), ('World', 'NOUN'), ('Cup', 'VERB'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'VERB'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'VERB'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'VERB'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'VERB'), ('Satellite', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 1 \n",
      "\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'DET'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'DET'), ('known', 'ADJ'), ('as', 'ADP'), ('tweets', 'DET'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'DET'), ('Satellite', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 2 \n",
      "\n",
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'NOUN'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'NOUN'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'NOUN'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'NOUN'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'NOUN'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 4 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Android', 'NOUN'), ('is', 'VERB'), ('a', 'DET'), ('mobile', 'ADJ'), ('operating', 'NOUN'), ('system', 'NOUN'), ('developed', 'VERB'), ('by', 'ADP'), ('Google', 'NOUN'), ('.', '.'), ('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.'), ('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.'), ('Twitter', 'NOUN'), ('is', 'VERB'), ('an', 'DET'), ('online', 'NOUN'), ('news', 'NOUN'), ('and', 'CONJ'), ('social', 'ADJ'), ('networking', 'NOUN'), ('service', 'NOUN'), ('on', 'ADP'), ('which', 'DET'), ('users', 'NOUN'), ('post', 'NOUN'), ('and', 'CONJ'), ('interact', 'NOUN'), ('with', 'ADP'), ('messages', 'VERB'), ('known', 'VERB'), ('as', 'ADP'), ('tweets', 'NOUN'), ('.', '.'), ('Before', 'ADP'), ('entering', 'VERB'), ('politics', 'NOUN'), (',', '.'), ('Donald', 'NOUN'), ('Trump', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('domineering', 'VERB'), ('businessman', 'NOUN'), ('and', 'CONJ'), ('a', 'DET'), ('television', 'NOUN'), ('personality', 'NOUN'), ('.', '.'), ('The', 'DET'), ('2018', 'NUM'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('is', 'VERB'), ('the', 'DET'), ('21st', 'NOUN'), ('FIFA', 'NOUN'), ('World', 'NOUN'), ('Cup', 'NOUN'), (',', '.'), ('an', 'DET'), ('international', 'ADJ'), ('football', 'NOUN'), ('tournament', 'NOUN'), ('contested', 'VERB'), ('once', 'ADV'), ('every', 'DET'), ('four', 'NUM'), ('years', 'NOUN'), ('.', '.'), ('This', 'DET'), ('is', 'VERB'), ('the', 'DET'), ('first', 'ADJ'), ('World', 'NOUN'), ('Cup', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Eastern', 'NOUN'), ('Europe', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('11th', 'ADJ'), ('time', 'NOUN'), ('that', 'ADP'), ('it', 'PRON'), ('has', 'VERB'), ('been', 'VERB'), ('held', 'VERB'), ('in', 'ADP'), ('Europe', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('cheapest', 'ADJ'), ('round', 'NOUN'), ('trips', 'NOUN'), ('from', 'ADP'), ('Dallas', 'NOUN'), ('to', 'PRT'), ('Atlanta', 'NOUN'), ('I', 'PRON'), ('would', 'VERB'), ('like', 'ADP'), ('to', 'PRT'), ('see', 'VERB'), ('flights', 'NOUN'), ('from', 'ADP'), ('Denver', 'NOUN'), ('to', 'PRT'), ('Philadelphia', 'NOUN'), ('.', '.'), ('Show', 'NOUN'), ('me', 'PRON'), ('the', 'DET'), ('price', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('flights', 'NOUN'), ('leaving', 'VERB'), ('Atlanta', 'NOUN'), ('at', 'ADP'), ('about', 'ADP'), ('3', 'NUM'), ('in', 'ADP'), ('the', 'DET'), ('afternoon', 'NOUN'), ('and', 'CONJ'), ('arriving', 'VERB'), ('in', 'ADP'), ('San', 'NOUN'), ('Francisco', 'NOUN'), ('.', '.'), ('NASA', 'NOUN'), ('invited', 'VERB'), ('social', 'ADJ'), ('media', 'NOUN'), ('users', 'NOUN'), ('to', 'PRT'), ('experience', 'NOUN'), ('the', 'DET'), ('launch', 'NOUN'), ('of', 'ADP'), ('ICESAT-2', 'NOUN'), ('Satellite', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "testing_unseen_data(model_dic, sample_test_words_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  26.540787935256958\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'VERB'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'VERB'),\n",
       " ('Android', 'VERB'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'VERB'),\n",
       " ('worldwide', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'VERB'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'VERB'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'VERB'),\n",
       " ('firehose.', 'VERB')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "\n",
    "* Android, Google, OS, Twitter's, Twitter, mobile, firehose : ADJ\n",
    "* deal, tablets, operating : NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  26.16862988471985\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq_1 = Viterbi_1(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'DET'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'DET'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'DET'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'DET'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'X'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'VERB'),\n",
       " ('firehose.', 'X')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq_1[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> All these cases were correctly POS tagged by Viterbi_1:\n",
    "* Android, OS, Twitter, deal, tablets, operating : NOUN\n",
    "* Twitter's : VERB\n",
    "* mobile : ADJ\n",
    "* Google, firehose: X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  26.264341354370117\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq_2 = Viterbi_2(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq_2[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> All these cases were correctly POS tagged by Viterbi_2:\n",
    "* Android, Google, OS, Twitter's, Twitter, firehose, deal, tablets, operating : NOUN\n",
    "* mobile, best-selling: ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  26.272080183029175\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq_4 = Viterbi_4(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq_4[:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'Red'> All these cases were correctly POS tagged by Viterbi_4:\n",
    "* Android, Google, OS, Twitter's, Twitter, firehose, tablets, operating, deal : NOUN\n",
    "* mobile : ADJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Green'>Step 8: Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Correct Accuracy</th>\n",
       "      <th>Incorrect Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanilla Viterbi</td>\n",
       "      <td>91.1504</td>\n",
       "      <td>8.8496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lexicon Unigram</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lexicon Bigram</td>\n",
       "      <td>21.7781</td>\n",
       "      <td>78.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lexicon Trigram</td>\n",
       "      <td>11.1328</td>\n",
       "      <td>88.8672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rule Base</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combine Lexicon Unigram Rule Base</td>\n",
       "      <td>90.6999</td>\n",
       "      <td>9.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Rule Base</td>\n",
       "      <td>91.0899</td>\n",
       "      <td>8.9101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combine Lexicon Unigram Bigram Trigram Rule Base</td>\n",
       "      <td>91.1094</td>\n",
       "      <td>8.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vanilla Viterbi 1</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>5.3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vanilla Viterbi 2</td>\n",
       "      <td>95.5752</td>\n",
       "      <td>4.4248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vanilla Viterbi 3</td>\n",
       "      <td>97.3451</td>\n",
       "      <td>2.6549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vanilla Viterbi 4</td>\n",
       "      <td>98.2301</td>\n",
       "      <td>1.7699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model Name  Correct Accuracy  \\\n",
       "0                                    Vanilla Viterbi           91.1504   \n",
       "1                                    Lexicon Unigram           90.6999   \n",
       "2                                     Lexicon Bigram           21.7781   \n",
       "3                                    Lexicon Trigram           11.1328   \n",
       "4                                          Rule Base            0.0000   \n",
       "5                 Combine Lexicon Unigram Rule Base            90.6999   \n",
       "6           Combine Lexicon Unigram Bigram Rule Base           91.0899   \n",
       "7   Combine Lexicon Unigram Bigram Trigram Rule Base           91.1094   \n",
       "8                                  Vanilla Viterbi 1           94.6903   \n",
       "9                                  Vanilla Viterbi 2           95.5752   \n",
       "10                                 Vanilla Viterbi 3           97.3451   \n",
       "11                                 Vanilla Viterbi 4           98.2301   \n",
       "\n",
       "    Incorrect Accuracy  \n",
       "0               8.8496  \n",
       "1               9.3001  \n",
       "2              78.2219  \n",
       "3              88.8672  \n",
       "4             100.0000  \n",
       "5               9.3001  \n",
       "6               8.9101  \n",
       "7               8.8906  \n",
       "8               5.3097  \n",
       "9               4.4248  \n",
       "10              2.6549  \n",
       "11              1.7699  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detail_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of vanilla Viterbi Algorithm: **89.3805%**\n",
    "\n",
    "The accuracy of vanilla Lexicon Unigram: **90.6999%**\n",
    "\n",
    "The accuracy of Combine Lexicon Unigram Bigram Trigram Rule Base: **91.1094%**\n",
    "\n",
    "\n",
    "The accuracy of modified Viterbi 1 Algorithm: **94.6903%**\n",
    "\n",
    "The accuracy of modified Viterbi 2 Algorithm: **95.5752%**\n",
    "\n",
    "The accuracy of modified Viterbi 3 Algorithm: **97.3451%**\n",
    "\n",
    "The accuracy of modified Viterbi 4 Algorithm: **98.2301%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'Green'>Step 8: List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "sentence_test1 = 'Google and Twitter made a deal in 2015 that gave Google access to Twitter\\'s firehose.'\n",
    "\n",
    "sentence_test2='Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'\n",
    "\n",
    "sentence_test3='I Instagrammed a Facebook post taken from Android smartphone and uploaded results to Youtube.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'Red'> Testing Multiple unseen data and  incorrectly tagged by original POS tagger and got corrected by your modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  Viterbi \n",
      "\n",
      "[('Google', 'VERB'), ('and', 'CONJ'), ('Twitter', 'VERB'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'VERB'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'VERB'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 1 \n",
      "\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'DET'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'X'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'VERB'), (\"'s\", 'PRT'), ('firehose', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 2 \n",
      "\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NOUN'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 4 \n",
      "\n",
      "[('Google', 'NOUN'), ('and', 'CONJ'), ('Twitter', 'NOUN'), ('made', 'VERB'), ('a', 'DET'), ('deal', 'NOUN'), ('in', 'ADP'), ('2015', 'NUM'), ('that', 'ADP'), ('gave', 'VERB'), ('Google', 'NOUN'), ('access', 'NOUN'), ('to', 'PRT'), ('Twitter', 'NOUN'), (\"'s\", 'PRT'), ('firehose', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "testing_unseen_data(model_dic, sentence_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  Viterbi \n",
      "\n",
      "[('Android', 'VERB'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'VERB'), ('worldwide', 'VERB'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'VERB'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 1 \n",
      "\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'DET'), ('since', 'ADP'), ('2011', 'DET'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'DET'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 2 \n",
      "\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'NOUN'), ('since', 'ADP'), ('2011', 'NOUN'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 4 \n",
      "\n",
      "[('Android', 'NOUN'), ('has', 'VERB'), ('been', 'VERB'), ('the', 'DET'), ('best-selling', 'ADJ'), ('OS', 'NOUN'), ('worldwide', 'NOUN'), ('on', 'ADP'), ('smartphones', 'VERB'), ('since', 'ADP'), ('2011', 'NUM'), ('and', 'CONJ'), ('on', 'ADP'), ('tablets', 'NOUN'), ('since', 'ADP'), ('2013', 'NUM'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "testing_unseen_data(model_dic, sentence_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name:  Viterbi \n",
      "\n",
      "[('I', 'PRON'), ('Instagrammed', 'VERB'), ('a', 'DET'), ('Facebook', 'VERB'), ('post', 'VERB'), ('taken', 'VERB'), ('from', 'ADP'), ('Android', 'VERB'), ('smartphone', 'VERB'), ('and', 'CONJ'), ('uploaded', 'VERB'), ('results', 'NOUN'), ('to', 'PRT'), ('Youtube', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 1 \n",
      "\n",
      "[('I', 'PRON'), ('Instagrammed', 'VERB'), ('a', 'DET'), ('Facebook', 'NOUN'), ('post', 'NOUN'), ('taken', 'VERB'), ('from', 'ADP'), ('Android', 'DET'), ('smartphone', 'NOUN'), ('and', 'CONJ'), ('uploaded', 'NOUN'), ('results', 'NOUN'), ('to', 'PRT'), ('Youtube', 'VERB'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 2 \n",
      "\n",
      "[('I', 'PRON'), ('Instagrammed', 'VERB'), ('a', 'DET'), ('Facebook', 'NOUN'), ('post', 'NOUN'), ('taken', 'VERB'), ('from', 'ADP'), ('Android', 'NOUN'), ('smartphone', 'NOUN'), ('and', 'CONJ'), ('uploaded', 'NOUN'), ('results', 'NOUN'), ('to', 'PRT'), ('Youtube', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n",
      "Model Name:  Viterbi 4 \n",
      "\n",
      "[('I', 'PRON'), ('Instagrammed', 'VERB'), ('a', 'DET'), ('Facebook', 'NOUN'), ('post', 'NOUN'), ('taken', 'VERB'), ('from', 'ADP'), ('Android', 'NOUN'), ('smartphone', 'NOUN'), ('and', 'CONJ'), ('uploaded', 'VERB'), ('results', 'NOUN'), ('to', 'PRT'), ('Youtube', 'NOUN'), ('.', '.')] \n",
      "\n",
      "*****************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "testing_unseen_data(model_dic, sentence_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = 'blue'>The following cases were incorrectly tagged which got corrected by modified Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* `*T*-252`: correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
